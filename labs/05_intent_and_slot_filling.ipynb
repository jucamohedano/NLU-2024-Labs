{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca7d9e5",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "<!-- - pytorch \n",
    "    - Pytorch install: https://pytorch.org/get-started/locally/ \n",
    "- tqdm\n",
    "- sklearn\n",
    "- Huggingface Transformer: \n",
    "    - pip install transformers  -->\n",
    "- **DATASET**:\n",
    "    - https://github.com/BrownFortress/IntentSlotDatasets\n",
    "    - We will use **ATIS** only\n",
    "    \n",
    "    \n",
    "\n",
    "## Outline\n",
    "\n",
    "#### Introduction\n",
    "- sequence labelling (Slot filling)\n",
    "- text classification (Intent classification)\n",
    "\n",
    "#### Preparing text for NN\n",
    "- word2id\n",
    "- special tokens \n",
    "- Customize Dataset class\n",
    "\n",
    "#### Split data in batches\n",
    "- Usage of Dataloader class\n",
    "- Padding sequences\n",
    "\n",
    "#### Neural Networks in Pytorch\n",
    "- Word embeddings\n",
    "- Implementation of an LSTM\n",
    "- Regularization techniques\n",
    "\n",
    "#### Train and Test a Neural Network\n",
    "- Optimizer\n",
    "- Loss function\n",
    "- Iteration over batches\n",
    "\n",
    "#### Hugging face library\n",
    "- Introduction and Usage\n",
    " \n",
    " \n",
    "## References\n",
    "- RNN: https://d2l.ai/chapter_recurrent-neural-networks/index.html \n",
    "- LSTM: https://d2l.ai/chapter_recurrent-modern/lstm.html\n",
    "- GRU: https://d2l.ai/chapter_recurrent-modern/gru.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c0b990",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/brownfortress/NLU-2024-labs/blob/main/labs/05_intent_and_slot_filling.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720a0554",
   "metadata": {},
   "source": [
    "# 1 Sequence Labeling,  Shallow Parsing and Text classification tasks\n",
    "\n",
    "## 1.1 Sequence Labeling and Shallow parsing\n",
    "Sequence labelling is to assign a label for each token. The task is formally defined as:\n",
    "- Given a sequence of tokens $w = {w_1, w_2, ..., w_n}$,\n",
    "- defining a sequence of labels as $l = {l_1, l_2, ..., l_n}$\n",
    "- compute the sequence $\\hat{l}$ such as $\\hat{l} = \\underset{l}{\\operatorname{argmax}} P(l|w)$ \n",
    "\n",
    "A particular case of sequence labelling is [Shallow Parsing](https://en.wikipedia.org/wiki/Shallow_parsing). The main difference from Sequence Labeling task is that Shallow Parsing performs __chunking__ -- segmentation of input sequence into constituents. Chunking is required to identify categories (or types) of *multi-word expressions*.\n",
    "\n",
    "In this, we are going to see a particular case of shallow parsing task, which is named as Slot Filling (or Concept tagging). The **segmentation** part is represented with IOB tags and the **labeling** part are the concepts defined in the annotation schema of a corpus. \\\n",
    "\\\n",
    "An example is the following: \n",
    "\n",
    "| Slot Filling |  |                     |                     |  |  |  |  |\n",
    "|------------------|----|--------------------------|--------------------------|---|------|---|--------|\n",
    "| Input sequence:  | on | april                    | first                    | I | want | a | flight |\n",
    "| Output sequence: | O  | B-depart_date.month_name | B-depart_date.day_number | O | O    | O | O      |\n",
    "\n",
    "## 1.2 Text classification\n",
    "The text classification problem is defined  as follows:\n",
    "- Given a sequence of tokens $w = {w_1, w_2, ..., w_n}$,\n",
    "- And a set of labels $L$ where $l \\in L$\n",
    "- estimate the label $\\hat{l}$ such as $\\hat{l} = \\underset{l}{\\operatorname{argmax}} P(l|w)$ \n",
    "\n",
    "In text classification, the label is given to the whole input sequence instead of at each element of the sequence (as in sequence labelling).\n",
    "\n",
    "The text classification task that we are going to see in this laboratory is named as Intent Classification. The Intent is an additional component of the *semantic frame*. \\\n",
    "\\\n",
    "An example is the following:\n",
    "\n",
    "| Intent Classification|  |                     |                     |  |  |  |  |\n",
    "|------------------|----|--------------------------|--------------------------|---|------|---|--------|\n",
    "| Input sequence:  | on | april                    | first                    | I | want | a | flight |\n",
    "| Output label: | flight     |\n",
    "\n",
    "\n",
    "# 2 Dataset\n",
    "The dataset that we are going to use is ATIS (Airline Travel Information Systems). It is composed of transcriptions of humans asking about flight information.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e3289e",
   "metadata": {},
   "source": [
    "## 2.2 Load the dataset\n",
    "I have prepared a custom data structure for this dataset. The structure is the following:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "    \"utterance\": \"on april first i need a flight going from phoenix to san diego\", \n",
    "    \"slots\": \"O B-depart_date.month_name B-depart_date.day_number O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name\", \n",
    "    \"intent\": \"flight\"\n",
    "    },\n",
    "    \"...\"\n",
    " ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70494a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using Colab, run these commands\n",
    "# !wget -P dataset/ATIS https://raw.githubusercontent.com/BrownFortress/IntentSlotDatasets/main/ATIS/test.json\n",
    "# !wget -P dataset/ATIS https://raw.githubusercontent.com/BrownFortress/IntentSlotDatasets/main/ATIS/train.json\n",
    "# !wget https://raw.githubusercontent.com/BrownFortress/NLU-2024-Labs/main/labs/conll.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80808524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "import os\n",
    "device = \"cuda:0\" #means we are using the GPU with id 0, if you have multiple GPU\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # Used to report errors on CUDA side\n",
    "PAD_TOKEN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1ea7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 4978\n",
      "Test samples: 893\n",
      "{'intent': 'flight',\n",
      " 'slots': 'O O O O O B-fromloc.city_name O B-depart_time.time '\n",
      "          'I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O '\n",
      "          'B-arrive_time.period_of_day',\n",
      " 'utterance': 'i want to fly from boston at 838 am and arrive in denver at '\n",
      "              '1110 in the morning'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "def load_data(path):\n",
    "    '''\n",
    "        input: path/to/data\n",
    "        output: json \n",
    "    '''\n",
    "    dataset = []\n",
    "    with open(path) as f:\n",
    "        dataset = json.loads(f.read())\n",
    "    return dataset\n",
    "\n",
    "tmp_train_raw = load_data(os.path.join('dataset','ATIS','train.json'))\n",
    "test_raw = load_data(os.path.join('dataset','ATIS','test.json'))\n",
    "print('Train samples:', len(tmp_train_raw))\n",
    "print('Test samples:', len(test_raw))\n",
    "\n",
    "pprint(tmp_train_raw[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b3f37",
   "metadata": {},
   "source": [
    "## 2.3 Create a dev set\n",
    "In the original split the development set (dev set) is missing. To train and find the best hyperparameter of our network the dev set is fundamental. Thus, we have to create it starting from the **traning** set. The dev set is usually the 10% of the dataset. \\\n",
    "Possible sampling strategies:\n",
    "* Take the last n elements of the training set.\n",
    "* Do a random sampling from the training set.\n",
    "* Do a stratified sampling from the training set using one or more criteria. (The best way)\n",
    "    * For further details look [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccd6da44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "{'abbreviation': 2.9000000000000004,\n",
      " 'aircraft': 1.6,\n",
      " 'airfare': 8.5,\n",
      " 'airline': 3.2,\n",
      " 'airline+flight_no': 0.0,\n",
      " 'airport': 0.4,\n",
      " 'capacity': 0.3,\n",
      " 'city': 0.4,\n",
      " 'distance': 0.4,\n",
      " 'flight': 73.7,\n",
      " 'flight+airfare': 0.4,\n",
      " 'flight_no': 0.2,\n",
      " 'flight_time': 1.0999999999999999,\n",
      " 'ground_fare': 0.4,\n",
      " 'ground_service': 5.1,\n",
      " 'meal': 0.1,\n",
      " 'quantity': 1.0,\n",
      " 'restriction': 0.1}\n",
      "Dev:\n",
      "{'abbreviation': 3.0,\n",
      " 'aircraft': 1.6,\n",
      " 'airfare': 8.4,\n",
      " 'airline': 3.2,\n",
      " 'airport': 0.4,\n",
      " 'capacity': 0.4,\n",
      " 'city': 0.4,\n",
      " 'distance': 0.4,\n",
      " 'flight': 73.7,\n",
      " 'flight+airfare': 0.4,\n",
      " 'flight_no': 0.2,\n",
      " 'flight_time': 1.0,\n",
      " 'ground_fare': 0.4,\n",
      " 'ground_service': 5.0,\n",
      " 'meal': 0.2,\n",
      " 'quantity': 1.0,\n",
      " 'restriction': 0.2}\n",
      "Test:\n",
      "{'abbreviation': 3.6999999999999997,\n",
      " 'aircraft': 1.0,\n",
      " 'airfare': 5.4,\n",
      " 'airfare+flight': 0.1,\n",
      " 'airline': 4.3,\n",
      " 'airport': 2.0,\n",
      " 'capacity': 2.4,\n",
      " 'city': 0.7000000000000001,\n",
      " 'day_name': 0.2,\n",
      " 'distance': 1.0999999999999999,\n",
      " 'flight': 70.8,\n",
      " 'flight+airfare': 1.3,\n",
      " 'flight+airline': 0.1,\n",
      " 'flight_no': 0.8999999999999999,\n",
      " 'flight_no+airline': 0.1,\n",
      " 'flight_time': 0.1,\n",
      " 'ground_fare': 0.8,\n",
      " 'ground_service': 4.0,\n",
      " 'meal': 0.7000000000000001,\n",
      " 'quantity': 0.3}\n",
      "=========================================================================================\n",
      "TRAIN size: 4480\n",
      "DEV size: 498\n",
      "TEST size: 893\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# First we get the 10% of the training set, then we compute the percentage of these examples \n",
    "\n",
    "portion = 0.10\n",
    "\n",
    "intents = [x['intent'] for x in tmp_train_raw] # We stratify on intents\n",
    "count_y = Counter(intents)\n",
    "\n",
    "labels = []\n",
    "inputs = []\n",
    "mini_train = []\n",
    "\n",
    "for id_y, y in enumerate(intents):\n",
    "    if count_y[y] > 1: # If some intents occurs only once, we put them in training\n",
    "        inputs.append(tmp_train_raw[id_y])\n",
    "        labels.append(y)\n",
    "    else:\n",
    "        mini_train.append(tmp_train_raw[id_y])\n",
    "# Random Stratify\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(inputs, labels, test_size=portion, \n",
    "                                                    random_state=42, \n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=labels)\n",
    "X_train.extend(mini_train)\n",
    "train_raw = X_train\n",
    "dev_raw = X_dev\n",
    "\n",
    "y_test = [x['intent'] for x in test_raw]\n",
    "\n",
    "# Intent distributions\n",
    "print('Train:')\n",
    "pprint({k:round(v/len(y_train),3)*100 for k, v in sorted(Counter(y_train).items())})\n",
    "print('Dev:'), \n",
    "pprint({k:round(v/len(y_dev),3)*100 for k, v in sorted(Counter(y_dev).items())})\n",
    "print('Test:') \n",
    "pprint({k:round(v/len(y_test),3)*100 for k, v in sorted(Counter(y_test).items())})\n",
    "print('='*89)\n",
    "# Dataset size\n",
    "print('TRAIN size:', len(train_raw))\n",
    "print('DEV size:', len(dev_raw))\n",
    "print('TEST size:', len(test_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76bbdbe",
   "metadata": {},
   "source": [
    "## 2.3 Convert words to numbers (word2id)\n",
    "Neural Networks in Pytorch, as in other libraries, work with numbers and vectors.\n",
    "<br><br>\n",
    "\n",
    "**Exercise 1** *(10 minutes)*\n",
    "* Create a dictionary that maps the words and labels in the training set to unique  integers $\\geq$ 0, called indexes.\n",
    "    That is:\n",
    "    - One dictionary for mapping words to ids (w2id)\n",
    "    - One dictionary for mapping slot labels to ids (slot2id)\n",
    "    - One dictionary for mapping intent labels to ids (intent2id)\n",
    "\n",
    "* With w2id map the sentence in `sent` into the computed indexes.\n",
    "\n",
    "***Example:***\n",
    "```python\n",
    "dictionary = {\"from\": 2, \"Boston\":88, \"to\":105, \"Tokyo\":42}\n",
    "sent = \"from Boston to Tokyo\" \n",
    "# Output:\n",
    "[2,88,105,42]\n",
    "```\n",
    "\n",
    "We will see later how to convert these indexes into vectors (aka embeddings).\n",
    "\n",
    "*Add special tokens \"pad\" and \"unk\"*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea03b2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "# Vocab: -1\n",
      "# Slots: 0\n",
      "# Intent: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "w2id = {'pad':PAD_TOKEN} # Pad tokens is 0 so the index count should start from 1\n",
    "slot2id = {'pad':PAD_TOKEN} # Pad tokens is 0 so the index count should start from 1\n",
    "intent2id = {}\n",
    "\n",
    "# Map the words only from the train set\n",
    "# Map slot and intent labels of train, dev and test set. 'unk' is not needed.\n",
    "sent = 'I wanna a flight from Toronto to Kuala Lumpur'\n",
    "\n",
    "mapping = [] # convert the sent into indexes using w2id\n",
    "print(mapping)\n",
    "\n",
    "print('# Vocab:', len(w2id)-2) # we remove pad and unk from the count\n",
    "print('# Slots:', len(slot2id)-1)\n",
    "print('# Intent:', len(intent2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9be408b",
   "metadata": {},
   "source": [
    "## 2.4 Lang class\n",
    "Later we will need to convert those numbers in the original form, so we need to invert those dictionaries. We create a class named as Lang just for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c04f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class Lang():\n",
    "    def __init__(self, words, intents, slots, cutoff=0):\n",
    "        self.word2id = self.w2id(words, cutoff=cutoff, unk=True)\n",
    "        self.slot2id = self.lab2id(slots)\n",
    "        self.intent2id = self.lab2id(intents, pad=False)\n",
    "        self.id2word = {v:k for k, v in self.word2id.items()}\n",
    "        self.id2slot = {v:k for k, v in self.slot2id.items()}\n",
    "        self.id2intent = {v:k for k, v in self.intent2id.items()}\n",
    "        \n",
    "    def w2id(self, elements, cutoff=None, unk=True):\n",
    "        vocab = {'pad': PAD_TOKEN}\n",
    "        if unk:\n",
    "            vocab['unk'] = len(vocab)\n",
    "        count = Counter(elements)\n",
    "        for k, v in count.items():\n",
    "            if v > cutoff:\n",
    "                vocab[k] = len(vocab)\n",
    "        return vocab\n",
    "    \n",
    "    def lab2id(self, elements, pad=True):\n",
    "        vocab = {}\n",
    "        if pad:\n",
    "            vocab['pad'] = PAD_TOKEN\n",
    "        for elem in elements:\n",
    "                vocab[elem] = len(vocab)\n",
    "        return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77bc3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sum([x['utterance'].split() for x in train_raw], []) # No set() since we want to compute \n",
    "                                                            # the cutoff\n",
    "corpus = train_raw + dev_raw + test_raw # We do not wat unk labels, \n",
    "                                        # however this depends on the research purpose\n",
    "slots = set(sum([line['slots'].split() for line in corpus],[]))\n",
    "intents = set([line['intent'] for line in corpus])\n",
    "\n",
    "lang = Lang(words, intents, slots, cutoff=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dbe8de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang.word2id['unk']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac746e",
   "metadata": {},
   "source": [
    "## 2.5 Customize the Dataset class\n",
    "In Pytorch the Dataset class helps you in handeling the dataset. The mandatory methods are ```__init__, __len__ and __getitem__```. <br>\n",
    "You can find more details here: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b4823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "class IntentsAndSlots (data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch dataset class for intent classification and slot filling tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Mandatory methods are __init__, __len__ and __getitem__\n",
    "    def __init__(self, dataset, lang, unk='unk'):\n",
    "        \"\"\"\n",
    "        Initialize the dataset by mapping utterances, slots, and intents to integer IDs.\n",
    "\n",
    "        :param dataset: List of dictionaries, each containing 'utterance', 'slots', and 'intent'.\n",
    "        :param lang: Language object containing mapping information.\n",
    "        :param unk: Unknown token (default is 'unk').\n",
    "        \"\"\"\n",
    "\n",
    "        self.utterances = []\n",
    "        self.intents = []\n",
    "        self.slots = []\n",
    "        self.unk = unk\n",
    "        \n",
    "        # Map utterances, slots, and intents to integer IDs\n",
    "        for x in dataset:\n",
    "            self.utterances.append(x['utterance'])\n",
    "            self.slots.append(x['slots'])\n",
    "            self.intents.append(x['intent'])\n",
    "\n",
    "        self.utt_ids = self.mapping_seq(self.utterances, lang.word2id)\n",
    "        self.slot_ids = self.mapping_seq(self.slots, lang.slot2id)\n",
    "        self.intent_ids = self.mapping_lab(self.intents, lang.intent2id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.utterances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return the dictionary for the example at index idx.\n",
    "\n",
    "        :param idx: Index of the example to retrieve.\n",
    "        :return: Dictionary containing 'utterance', 'slots', and 'intent' as integer IDs.\n",
    "        \"\"\"\n",
    "        utt = torch.Tensor(self.utt_ids[idx])\n",
    "        slots = torch.Tensor(self.slot_ids[idx])\n",
    "        intent = self.intent_ids[idx]\n",
    "        sample = {'utterance': utt, 'slots': slots, 'intent': intent}\n",
    "        return sample\n",
    "    \n",
    "    # Auxiliary methods\n",
    "    \n",
    "    def mapping_lab(self, data, mapper):\n",
    "        \"\"\"\n",
    "        Map a list of labels to integer IDs, using the unknown token ID if not found in mapper.\n",
    "\n",
    "        :param data: List of labels.\n",
    "        :param mapper: Mapper dictionary.\n",
    "        :return: List of integer IDs.\n",
    "        \"\"\"\n",
    "        return [mapper[x] if x in mapper else mapper[self.unk] for x in data]\n",
    "    \n",
    "    def mapping_seq(self, data, mapper): # Map sequences to number\n",
    "        \"\"\"\n",
    "        Map a list of sequences to integer IDs, tokenizing each sequence.\n",
    "\n",
    "        :param data: List of sequences.\n",
    "        :param mapper: Mapper dictionary.\n",
    "        :return: List of tokenized and mapped sequences.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for seq in data:\n",
    "            tmp_seq = []\n",
    "            for x in seq.split():\n",
    "                if x in mapper:\n",
    "                    tmp_seq.append(mapper[x])\n",
    "                else:\n",
    "                    tmp_seq.append(mapper[self.unk])\n",
    "            res.append(tmp_seq)\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "459376d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'unk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y136sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lang\u001b[39m.\u001b[39;49mintent2id[\u001b[39m'\u001b[39;49m\u001b[39munk\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'unk'"
     ]
    }
   ],
   "source": [
    "lang.intent2id['unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "845ab541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our datasets\n",
    "train_dataset = IntentsAndSlots(train_raw, lang)\n",
    "dev_dataset = IntentsAndSlots(dev_raw, lang)\n",
    "test_dataset = IntentsAndSlots(test_raw, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6630cc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': tensor([ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]),\n",
       " 'slots': tensor([121., 121., 121., 121., 121., 121., 121., 121., 101., 121., 126.]),\n",
       " 'intent': 19}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d297a312",
   "metadata": {},
   "source": [
    "# 3 Batches\n",
    "Batches are used to handle large datasets in the memory. Since the whole dataset cannot fit in GPU memories, we randomly shuffle the dataset and we split it in small batches that will be processed one at a time.\n",
    "## 3.1 Padding\n",
    "Padding is a strategy to fit sequences of different lengths into a matrix. For instance:\n",
    "\n",
    "| Right padding|   |    |   |  |  |  |  \n",
    "|---|----|---|---|---|------|---|\n",
    "| I | saw| a | unk | with | a | telescope | \n",
    "| book | me | a | flight | [pad] | [pad] | [pad] | \n",
    "\n",
    "| Left padding|   |    |   |  |  |  |  \n",
    "|---|----|---|---|---|------|---|\n",
    "| I | saw| a | unk | with | a | telescope | \n",
    "| [pad] | [pad] | [pad] | book | me | a | flight | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874eb4c4",
   "metadata": {},
   "source": [
    "**Exercise 2** *(5 minutes)* <br> \n",
    "Write a function that adds padding on the right. (No need to convert the sentences to numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71bb2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split them by white space\n",
    "sequences = ['I saw a man with a telescope', \n",
    "             'book me a flight', \n",
    "             'I want to see the flights from Milan to Ibiza']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b71d2",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "To split the dataset into batches and add padding we will use the DataLoader class. \n",
    "```python\n",
    "DataLoader(Dataset, batch_size=N, collate_fn={custom function}, shuffle=True)\n",
    "```\n",
    "*collate_fn* is used to shape the output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7105180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(data):\n",
    "    # print(len(data[0]))\n",
    "    # print(data[0].keys())\n",
    "    # print(data[0][\"utterance\"])\n",
    "\n",
    "    def merge(sequences):\n",
    "        '''\n",
    "        merge from batch * sent_len to batch * max_len \n",
    "        '''\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        max_len = 1 if max(lengths)==0 else max(lengths)\n",
    "        # Pad token is zero in our case\n",
    "        # So we create a matrix full of PAD_TOKEN (i.e. 0) with the shape \n",
    "        # batch_size X maximum length of a sequence\n",
    "        padded_seqs = torch.LongTensor(len(sequences),max_len).fill_(PAD_TOKEN)\n",
    "        for i, seq in enumerate(sequences):\n",
    "            end = lengths[i]\n",
    "            padded_seqs[i, :end] = seq # We copy each sequence into the matrix\n",
    "        # print(padded_seqs)\n",
    "        padded_seqs = padded_seqs.detach()  # We remove these tensors from the computational graph\n",
    "        return padded_seqs, lengths\n",
    "    # Sort data by seq lengths\n",
    "    data.sort(key=lambda x: len(x['utterance']), reverse=True) \n",
    "    new_item = {}\n",
    "    for key in data[0].keys():\n",
    "        new_item[key] = [d[key] for d in data]\n",
    "        \n",
    "    # print(len(new_item))\n",
    "    # print([d[key] for d in data])\n",
    "    # print(new_item[\"utterance\"])\n",
    "    # We just need one length for packed pad seq, since len(utt) == len(slots)\n",
    "    src_utt, _ = merge(new_item['utterance'])\n",
    "    y_slots, y_lengths = merge(new_item[\"slots\"])\n",
    "    intent = torch.LongTensor(new_item[\"intent\"])\n",
    "    \n",
    "    src_utt = src_utt.to(device) # We load the Tensor on our selected device\n",
    "    y_slots = y_slots.to(device)\n",
    "    intent = intent.to(device)\n",
    "    y_lengths = torch.LongTensor(y_lengths).to(device)\n",
    "    \n",
    "    new_item[\"utterances\"] = src_utt\n",
    "    new_item[\"intents\"] = intent\n",
    "    new_item[\"y_slots\"] = y_slots\n",
    "    new_item[\"slots_len\"] = y_lengths\n",
    "    return new_item\n",
    "\n",
    "# Dataloader instantiations\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, collate_fn=collate_fn,  shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=64, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e459effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization example for the data in the previous cell\n",
    "# For help. Right before calling merge, this is how the data dictionaries that we have look like.\n",
    "data = [\n",
    "    {'utterance': ['Hello'], 'slots': ['Greeting'], 'intent': 'greet'},\n",
    "    {'utterance': ['How are you?'], 'slots': ['Greeting'], 'intent': 'greet'},\n",
    "    {'utterance': ['Goodbye'], 'slots': ['Farewell'], 'intent': 'farewell'}\n",
    "]\n",
    "\n",
    "# After running the for loop we get:\n",
    "new_item = {\n",
    "    'utterance': [['Hello'], ['How are you?'], ['Goodbye']],\n",
    "    'slots': [['Greeting'], ['Greeting'], ['Farewell']],\n",
    "    'intent': ['greet', 'greet', 'farewell']\n",
    "}\n",
    "# then the next step would be merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019e479",
   "metadata": {},
   "source": [
    "# 4 Define a neural network in Pytorch\n",
    "In PyTorch the definition of a neural network is quite flexible. In ```__init__``` the layer that is going to be used are instantiated. In ```forward```, the architecture of the neural network is defined. Here you can find all the layers provided by Pytorch https://pytorch.org/docs/stable/nn.html while here you can find the recurrent layers https://pytorch.org/docs/stable/nn.html#recurrent-layers. \n",
    "\n",
    "<br><br>\n",
    "**pack_padded_sequence** and **pad_packed_sequences** respectively compress and uncompress sequences to remove the padding embeddings from the computation, reducing the computational cost and, therefore, the CO2 emissions.\n",
    " ![](https://i.stack.imgur.com/LPHAs.jpg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93adc878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class ModelIAS(nn.Module):\n",
    "\n",
    "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=1, pad_index=0):\n",
    "        super(ModelIAS, self).__init__()\n",
    "        # hid_size = Hidden size\n",
    "        # out_slot = number of slots (output size for slot filling)\n",
    "        # out_int = number of intents (output size for intent class)\n",
    "        # emb_size = word embedding size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_len, emb_size, padding_idx=pad_index)\n",
    "        \n",
    "        self.utt_encoder = nn.LSTM(emb_size, hid_size, n_layer, bidirectional=False, batch_first=True)\n",
    "        self.slot_out = nn.Linear(hid_size, out_slot)\n",
    "        self.intent_out = nn.Linear(hid_size, out_int)\n",
    "        # Dropout layer How/Where do we apply it?\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, utterance, seq_lengths):\n",
    "        # utterance.size() = batch_size X seq_len\n",
    "        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
    "        \n",
    "        utt_emb = self.dropout(utt_emb) # we can use dropout after the embedding layer\n",
    "\n",
    "        # pack_padded_sequence avoid computation over pad tokens reducing the computational cost\n",
    "        #.cpu().numpy() converts the seq_lengths tensor to a NumPy array and moves it to the CPU memory\n",
    "        # This is done because pack_padded_sequence expects the sequence lengths to be provided as a CPU-based NumPy array.\n",
    "        packed_input = pack_padded_sequence(utt_emb, seq_lengths.cpu().numpy(), batch_first=True)\n",
    "        # Process the batch\n",
    "        packed_output, (last_hidden, cell) = self.utt_encoder(packed_input) \n",
    "\n",
    "        # Unpack the sequence\n",
    "        utt_encoded, input_sizes = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        utt_emb = self.dropout(utt_encoded) # we can use dropout after the LSTM layer too!\n",
    "        \n",
    "        # Get the last hidden state\n",
    "        last_hidden = last_hidden[-1,:,:]\n",
    "        \n",
    "        # Is this another possible way to get the last hiddent state? (Why?)\n",
    "        # utt_encoded.permute(1,0,2)[-1]\n",
    "        \n",
    "        # Compute slot logits\n",
    "        slots = self.slot_out(utt_encoded)\n",
    "        # Compute intent logits\n",
    "        intent = self.intent_out(last_hidden)\n",
    "        \n",
    "        # Slot size: batch_size, seq_len, classes \n",
    "        slots = slots.permute(0,2,1) # We need this for computing the loss\n",
    "        # Slot size: batch_size, classes, seq_len\n",
    "        return slots, intent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a1ecc",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "- Why do we pad the sequences twice? \n",
    "  - First time in the merge function above\n",
    "  - Second time in the forward function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c992a22c",
   "metadata": {},
   "source": [
    "## 3.1 Function to randomly initialize the weights\n",
    "This is a generic function that randomly initialize the parameters of RNN networks and linear layers. To dig deep in to this I would suggest you to look at here: https://pytorch.org/docs/master/nn.init.html \\\n",
    "\\\n",
    "*Note: In Pytorch every parameter of the network has a proper name like weight_ih, weight_hh etc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f47fe3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(mat):\n",
    "    for m in mat.modules():\n",
    "        if type(m) in [nn.GRU, nn.LSTM, nn.RNN]:\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    for idx in range(4):\n",
    "                        mul = param.shape[0]//4\n",
    "                        torch.nn.init.xavier_uniform_(param[idx*mul:(idx+1)*mul])\n",
    "                elif 'weight_hh' in name:\n",
    "                    for idx in range(4):\n",
    "                        mul = param.shape[0]//4\n",
    "                        torch.nn.init.orthogonal_(param[idx*mul:(idx+1)*mul])\n",
    "                elif 'bias' in name:\n",
    "                    param.data.fill_(0)\n",
    "        else:\n",
    "            if type(m) in [nn.Linear]:\n",
    "                torch.nn.init.uniform_(m.weight, -0.01, 0.01)\n",
    "                if m.bias != None:\n",
    "                    m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a362fc",
   "metadata": {},
   "source": [
    "## 3.2 Training set up\n",
    "We initialize the model and we select the hyperparameters of the neural network. Futhermore, we initialize the optimizer and we select the loss function.\n",
    "- You can find further optimization algorithms here: https://pytorch.org/docs/stable/optim.html\n",
    "- and further loss functions here: https://pytorch.org/docs/stable/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e5edf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "hid_size = 200\n",
    "emb_size = 300\n",
    "\n",
    "lr = 0.0001 # learning rate\n",
    "clip = 5 # Clip the gradient\n",
    "\n",
    "out_slot = len(lang.slot2id)\n",
    "out_int = len(lang.intent2id)\n",
    "vocab_len = len(lang.word2id)\n",
    "\n",
    "model = ModelIAS(hid_size, out_slot, out_int, emb_size, vocab_len, pad_index=PAD_TOKEN).to(device)\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "criterion_intents = nn.CrossEntropyLoss() # Because we do not have the pad token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a18f4",
   "metadata": {},
   "source": [
    "### Train Loop and Evaluation Loop\n",
    "We define two functions one for training our model and the other for evaluating it. To compute the performances on the slot filling task we will use the **conll script**, while for the intent classification task we are going to use the **classification_report**.\n",
    "\n",
    "<br>\n",
    "\n",
    "In the literature, the Intent Classification task is evaluated using accuracy as a metric. The Slot filling task is evaluated using the *conll script* which computes the performance at the chunk level and the F1 score is usually reported. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef292a1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### <font color='blue'>Note on gradient clipping</font>\n",
    "\n",
    "torch.nn.utils.clip_grad_norm_(...): This function clips the gradients of the model's parameters. It ensures that the norm of the gradients does not exceed the specified clip value.\n",
    "Gradient Clipping:\n",
    "For each parameter tensor in the model, the function computes the L2-norm (Euclidean norm) of the gradient.\n",
    "If the norm of the gradient exceeds the clip value, the gradient tensor is rescaled to have a norm equal to clip.\n",
    "In the provided code, torch.nn.utils.clip_grad_norm_() is used to ensure that the L2-norm of the gradients does not exceed the specified clip value, effectively limiting the maximum allowed gradient magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bf6dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conll import evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_loop(data, optimizer, criterion_slots, criterion_intents, model, clip=5):\n",
    "    model.train()\n",
    "    loss_array = []\n",
    "    for sample in data:\n",
    "        optimizer.zero_grad() # Zeroing the gradient\n",
    "        slots, intent = model(sample['utterances'], sample['slots_len'])\n",
    "        loss_intent = criterion_intents(intent, sample['intents'])\n",
    "        loss_slot = criterion_slots(slots, sample['y_slots'])\n",
    "        loss = loss_intent + loss_slot # In joint training we sum the losses. \n",
    "                                       # Is there another way to do that?\n",
    "        loss_array.append(loss.item())\n",
    "        loss.backward() # Compute the gradient, deleting the computational graph\n",
    "        # clip the gradient to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  \n",
    "        optimizer.step() # Update the weights\n",
    "    return loss_array\n",
    "\n",
    "def eval_loop(data, criterion_slots, criterion_intents, model, lang):\n",
    "    model.eval()\n",
    "    loss_array = []\n",
    "    \n",
    "    ref_intents = []\n",
    "    hyp_intents = []\n",
    "    \n",
    "    ref_slots = []\n",
    "    hyp_slots = []\n",
    "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
    "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
    "        for sample in data:\n",
    "            slots, intents = model(sample['utterances'], sample['slots_len'])\n",
    "            loss_intent = criterion_intents(intents, sample['intents'])\n",
    "            loss_slot = criterion_slots(slots, sample['y_slots'])\n",
    "            loss = loss_intent + loss_slot \n",
    "            loss_array.append(loss.item())\n",
    "            # Intent inference\n",
    "            # Get the highest probable class\n",
    "            out_intents = [lang.id2intent[x] \n",
    "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
    "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
    "            ref_intents.extend(gt_intents)\n",
    "            hyp_intents.extend(out_intents)\n",
    "            \n",
    "            # Slot inference\n",
    "            output_slots = torch.argmax(slots, dim=1)\n",
    "            for id_seq, seq in enumerate(output_slots):\n",
    "                length = sample['slots_len'].tolist()[id_seq]\n",
    "                utt_ids = sample['utterance'][id_seq][:length].tolist()\n",
    "                gt_ids = sample['y_slots'][id_seq].tolist()\n",
    "                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n",
    "                utterance = [lang.id2word[elem] for elem in utt_ids]\n",
    "                to_decode = seq[:length].tolist()\n",
    "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
    "                tmp_seq = []\n",
    "                for id_el, elem in enumerate(to_decode):\n",
    "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]))\n",
    "                hyp_slots.append(tmp_seq)\n",
    "    try:            \n",
    "        results = evaluate(ref_slots, hyp_slots)\n",
    "    except Exception as ex:\n",
    "        # Sometimes the model predicts a class that is not in REF\n",
    "        print(\"Warning:\", ex)\n",
    "        ref_s = set([x[1] for x in ref_slots])\n",
    "        hyp_s = set([x[1] for x in hyp_slots])\n",
    "        print(hyp_s.difference(ref_s))\n",
    "        results = {\"total\":{\"f\":0}}\n",
    "        \n",
    "    report_intent = classification_report(ref_intents, hyp_intents, \n",
    "                                          zero_division=False, output_dict=True)\n",
    "    return results, report_intent, loss_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2eaee",
   "metadata": {},
   "source": [
    "## 3.3 Train a neural network\n",
    "We train a neural network iterating several times over the training set. \n",
    "* **epochs**: number of times in which the whole training set is seen by the network\n",
    "* **early stopping**: keeps controlled the performance of the model on the dev set and interrupts the training when the performance is getting worse\n",
    "    * **patience**: wait for a number of step before interrupting the training, even though the performance is getting worse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d07777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:00<00:07,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: None\n",
      "{('time', 'O'), ('could', 'B-arrive_time.period_of_day'), ('united', 'B-toloc.city_name'), ('northwest', 'O'), ('list', 'B-round_trip'), ('you', 'B-airline_name'), ('seventh', 'O'), ('give', 'I-restriction_code'), ('much', 'B-fromloc.city_name'), ('nonstop', 'O'), ('washington', 'O'), ('new', 'O'), ('midwest', 'O'), ('atlanta', 'O'), ('fares', 'I-cost_relative'), ('prices', 'I-fromloc.city_name'), ('you', 'B-depart_time.period_of_day'), ('would', 'I-arrive_time.time'), ('twa', 'O'), ('friday', 'B-flight'), ('departures', 'B-flight_stop'), ('there', 'B-toloc.city_name'), ('las', 'O'), ('do', 'I-toloc.city_name'), ('francisco', 'I-toloc.city_name'), ('all', 'B-fromloc.city_name'), ('transport', 'I-depart_time.time'), ('live', 'B-depart_time.period_mod'), ('any', 'B-depart_date.month_name'), ('travel', 'B-arrive_time.start_time'), ('arrange', 'B-fromloc.city_name'), ('sunday', 'I-fromloc.city_name'), ('august', 'O'), ('airlines', 'I-airline_name'), ('information', 'B-depart_time.period_of_day'), ('types', 'B-return_date.today_relative'), ('about', 'B-fromloc.city_name'), ('give', 'B-depart_date.day_number'), ('of', 'B-depart_time.period_of_day'), ('pittsburgh', 'B-fromloc.city_name'), ('united', 'O'), ('limousine', 'O'), ('an', 'B-fromloc.city_name')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:01<00:04,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cor': 22, 'hyp': 161, 'ref': 1692}\n",
      "{'fromloc.city_name': {'cor': 4, 'hyp': 29, 'ref': 424}, 'toloc.city_name': {'cor': 3, 'hyp': 59, 'ref': 444}, 'stoploc.city_name': {'cor': 0, 'hyp': 0, 'ref': 27}, 'flight_time': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 91}, 'depart_date.month_name': {'cor': 0, 'hyp': 4, 'ref': 43}, 'depart_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_time.period_mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.period_of_day': {'cor': 7, 'hyp': 10, 'ref': 60}, 'or': {'cor': 0, 'hyp': 0, 'ref': 6}, 'depart_time.start_time': {'cor': 0, 'hyp': 7, 'ref': 4}, 'arrive_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 20}, 'arrive_time.time': {'cor': 0, 'hyp': 0, 'ref': 20}, 'flight_stop': {'cor': 0, 'hyp': 0, 'ref': 14}, 'meal': {'cor': 0, 'hyp': 0, 'ref': 9}, 'airline_name': {'cor': 6, 'hyp': 17, 'ref': 70}, 'flight_number': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_time.time': {'cor': 0, 'hyp': 1, 'ref': 37}, 'flight_mod': {'cor': 0, 'hyp': 1, 'ref': 29}, 'return_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 2}, 'cost_relative': {'cor': 0, 'hyp': 0, 'ref': 41}, 'round_trip': {'cor': 2, 'hyp': 2, 'ref': 38}, 'class_type': {'cor': 0, 'hyp': 1, 'ref': 20}, 'depart_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 35}, 'airline_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'state_name': {'cor': 0, 'hyp': 2, 'ref': 0}, 'meal_description': {'cor': 0, 'hyp': 2, 'ref': 6}, 'restriction_code': {'cor': 0, 'hyp': 16, 'ref': 3}, 'fromloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 6}, 'toloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 10}, 'toloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'transport_type': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 11}, 'depart_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 9}, 'economy': {'cor': 0, 'hyp': 2, 'ref': 5}, 'fare_basis_code': {'cor': 0, 'hyp': 0, 'ref': 7}, 'city_name': {'cor': 0, 'hyp': 0, 'ref': 22}, 'airport_code': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_time.start_time': {'cor': 0, 'hyp': 2, 'ref': 4}, 'arrive_date.day_name': {'cor': 0, 'hyp': 1, 'ref': 7}, 'fare_amount': {'cor': 0, 'hyp': 0, 'ref': 8}, 'arrive_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'airport_name': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'fromloc.airport_code': {'cor': 0, 'hyp': 2, 'ref': 1}, 'day_name': {'cor': 0, 'hyp': 0, 'ref': 3}, 'month_name': {'cor': 0, 'hyp': 0, 'ref': 2}, 'day_number': {'cor': 0, 'hyp': 0, 'ref': 2}, 'arrive_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'connect': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'mod': {'cor': 0, 'hyp': 1, 'ref': 4}, 'toloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'depart_date.today_relative': {'cor': 0, 'hyp': 0, 'ref': 7}, 'days_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'aircraft_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'stoploc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'depart_date.year': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.month_name': {'cor': 0, 'hyp': 2, 'ref': 1}, 'return_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 1}, 'flight_days': {'cor': 0, 'hyp': 0, 'ref': 1}, 'stoploc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:01<00:03,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cor': 3, 'hyp': 58, 'ref': 1692}\n",
      "{'fromloc.city_name': {'cor': 0, 'hyp': 8, 'ref': 424}, 'toloc.city_name': {'cor': 0, 'hyp': 17, 'ref': 444}, 'stoploc.city_name': {'cor': 0, 'hyp': 0, 'ref': 27}, 'flight_time': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_date.day_name': {'cor': 0, 'hyp': 3, 'ref': 91}, 'depart_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_time.period_mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.period_of_day': {'cor': 1, 'hyp': 1, 'ref': 60}, 'or': {'cor': 0, 'hyp': 0, 'ref': 6}, 'arrive_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 20}, 'arrive_time.time': {'cor': 0, 'hyp': 0, 'ref': 20}, 'flight_stop': {'cor': 0, 'hyp': 0, 'ref': 14}, 'meal': {'cor': 0, 'hyp': 0, 'ref': 9}, 'airline_name': {'cor': 2, 'hyp': 4, 'ref': 70}, 'flight_number': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_time.time': {'cor': 0, 'hyp': 0, 'ref': 37}, 'flight_mod': {'cor': 0, 'hyp': 1, 'ref': 29}, 'return_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 2}, 'cost_relative': {'cor': 0, 'hyp': 0, 'ref': 41}, 'round_trip': {'cor': 0, 'hyp': 2, 'ref': 38}, 'class_type': {'cor': 0, 'hyp': 0, 'ref': 20}, 'depart_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 35}, 'airline_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'meal_description': {'cor': 0, 'hyp': 2, 'ref': 6}, 'restriction_code': {'cor': 0, 'hyp': 16, 'ref': 3}, 'fromloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 6}, 'toloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 10}, 'toloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'transport_type': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 11}, 'depart_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 9}, 'economy': {'cor': 0, 'hyp': 0, 'ref': 5}, 'fare_basis_code': {'cor': 0, 'hyp': 0, 'ref': 7}, 'city_name': {'cor': 0, 'hyp': 0, 'ref': 22}, 'airport_code': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_time.start_time': {'cor': 0, 'hyp': 2, 'ref': 4}, 'arrive_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 7}, 'fare_amount': {'cor': 0, 'hyp': 0, 'ref': 8}, 'arrive_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'airport_name': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'day_name': {'cor': 0, 'hyp': 0, 'ref': 3}, 'month_name': {'cor': 0, 'hyp': 0, 'ref': 2}, 'day_number': {'cor': 0, 'hyp': 0, 'ref': 2}, 'arrive_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'connect': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'toloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'depart_date.today_relative': {'cor': 0, 'hyp': 0, 'ref': 7}, 'days_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'fromloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'aircraft_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'stoploc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'depart_date.year': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.month_name': {'cor': 0, 'hyp': 2, 'ref': 1}, 'return_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 1}, 'flight_days': {'cor': 0, 'hyp': 0, 'ref': 1}, 'stoploc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:02<00:02,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cor': 3, 'hyp': 20, 'ref': 1692}\n",
      "{'fromloc.city_name': {'cor': 0, 'hyp': 2, 'ref': 424}, 'toloc.city_name': {'cor': 0, 'hyp': 4, 'ref': 444}, 'stoploc.city_name': {'cor': 0, 'hyp': 0, 'ref': 27}, 'flight_time': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_date.day_name': {'cor': 0, 'hyp': 2, 'ref': 91}, 'depart_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_time.period_mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.period_of_day': {'cor': 1, 'hyp': 1, 'ref': 60}, 'or': {'cor': 0, 'hyp': 0, 'ref': 6}, 'arrive_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 20}, 'arrive_time.time': {'cor': 0, 'hyp': 0, 'ref': 20}, 'flight_stop': {'cor': 0, 'hyp': 0, 'ref': 14}, 'meal': {'cor': 0, 'hyp': 0, 'ref': 9}, 'airline_name': {'cor': 2, 'hyp': 4, 'ref': 70}, 'flight_number': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_time.time': {'cor': 0, 'hyp': 0, 'ref': 37}, 'flight_mod': {'cor': 0, 'hyp': 1, 'ref': 29}, 'return_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 2}, 'cost_relative': {'cor': 0, 'hyp': 0, 'ref': 41}, 'round_trip': {'cor': 0, 'hyp': 2, 'ref': 38}, 'class_type': {'cor': 0, 'hyp': 0, 'ref': 20}, 'depart_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 35}, 'airline_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'meal_description': {'cor': 0, 'hyp': 2, 'ref': 6}, 'fromloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 6}, 'toloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 10}, 'toloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'transport_type': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 11}, 'depart_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 9}, 'economy': {'cor': 0, 'hyp': 0, 'ref': 5}, 'fare_basis_code': {'cor': 0, 'hyp': 0, 'ref': 7}, 'city_name': {'cor': 0, 'hyp': 0, 'ref': 22}, 'restriction_code': {'cor': 0, 'hyp': 0, 'ref': 3}, 'airport_code': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 7}, 'fare_amount': {'cor': 0, 'hyp': 0, 'ref': 8}, 'arrive_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'arrive_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'airport_name': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'day_name': {'cor': 0, 'hyp': 0, 'ref': 3}, 'month_name': {'cor': 0, 'hyp': 0, 'ref': 2}, 'day_number': {'cor': 0, 'hyp': 0, 'ref': 2}, 'arrive_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'connect': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'toloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'depart_date.today_relative': {'cor': 0, 'hyp': 0, 'ref': 7}, 'days_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'fromloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'aircraft_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'stoploc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'depart_date.year': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.month_name': {'cor': 0, 'hyp': 2, 'ref': 1}, 'return_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 1}, 'flight_days': {'cor': 0, 'hyp': 0, 'ref': 1}, 'stoploc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:02<00:03,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cor': 4, 'hyp': 14, 'ref': 1692}\n",
      "{'fromloc.city_name': {'cor': 0, 'hyp': 0, 'ref': 424}, 'toloc.city_name': {'cor': 0, 'hyp': 3, 'ref': 444}, 'stoploc.city_name': {'cor': 0, 'hyp': 0, 'ref': 27}, 'flight_time': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 91}, 'depart_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_time.period_mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.period_of_day': {'cor': 2, 'hyp': 3, 'ref': 60}, 'or': {'cor': 0, 'hyp': 0, 'ref': 6}, 'arrive_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 20}, 'arrive_time.time': {'cor': 0, 'hyp': 0, 'ref': 20}, 'flight_stop': {'cor': 0, 'hyp': 0, 'ref': 14}, 'meal': {'cor': 0, 'hyp': 0, 'ref': 9}, 'airline_name': {'cor': 2, 'hyp': 3, 'ref': 70}, 'flight_number': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_time.time': {'cor': 0, 'hyp': 0, 'ref': 37}, 'flight_mod': {'cor': 0, 'hyp': 1, 'ref': 29}, 'return_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 2}, 'cost_relative': {'cor': 0, 'hyp': 0, 'ref': 41}, 'round_trip': {'cor': 0, 'hyp': 2, 'ref': 38}, 'class_type': {'cor': 0, 'hyp': 0, 'ref': 20}, 'depart_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 35}, 'airline_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'meal_description': {'cor': 0, 'hyp': 0, 'ref': 6}, 'fromloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 6}, 'toloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 10}, 'toloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'transport_type': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 11}, 'depart_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 9}, 'economy': {'cor': 0, 'hyp': 0, 'ref': 5}, 'fare_basis_code': {'cor': 0, 'hyp': 0, 'ref': 7}, 'city_name': {'cor': 0, 'hyp': 0, 'ref': 22}, 'restriction_code': {'cor': 0, 'hyp': 0, 'ref': 3}, 'airport_code': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 7}, 'fare_amount': {'cor': 0, 'hyp': 0, 'ref': 8}, 'arrive_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'arrive_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'airport_name': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'day_name': {'cor': 0, 'hyp': 0, 'ref': 3}, 'month_name': {'cor': 0, 'hyp': 0, 'ref': 2}, 'day_number': {'cor': 0, 'hyp': 0, 'ref': 2}, 'arrive_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'connect': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'toloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'depart_date.today_relative': {'cor': 0, 'hyp': 0, 'ref': 7}, 'days_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'fromloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'aircraft_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'stoploc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'depart_date.year': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.month_name': {'cor': 0, 'hyp': 2, 'ref': 1}, 'return_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 1}, 'flight_days': {'cor': 0, 'hyp': 0, 'ref': 1}, 'stoploc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}}\n",
      "{'cor': 3, 'hyp': 21, 'ref': 2837}\n",
      "{'depart_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 17}, 'depart_date.day_name': {'cor': 0, 'hyp': 3, 'ref': 212}, 'fromloc.city_name': {'cor': 0, 'hyp': 0, 'ref': 704}, 'toloc.city_name': {'cor': 0, 'hyp': 1, 'ref': 716}, 'arrive_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 31}, 'arrive_time.time': {'cor': 0, 'hyp': 0, 'ref': 34}, 'return_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 2}, 'toloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 28}, 'arrive_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 6}, 'arrive_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 6}, 'arrive_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 8}, 'arrive_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 8}, 'stoploc.city_name': {'cor': 0, 'hyp': 0, 'ref': 20}, 'depart_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 56}, 'depart_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 55}, 'airline_name': {'cor': 1, 'hyp': 6, 'ref': 101}, 'depart_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 65}, 'depart_time.time': {'cor': 0, 'hyp': 0, 'ref': 57}, 'round_trip': {'cor': 0, 'hyp': 1, 'ref': 73}, 'return_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 3}, 'depart_time.period_of_day': {'cor': 2, 'hyp': 4, 'ref': 130}, 'flight_stop': {'cor': 0, 'hyp': 0, 'ref': 21}, 'arrive_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 6}, 'fromloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 12}, 'meal': {'cor': 0, 'hyp': 0, 'ref': 16}, 'flight_number': {'cor': 0, 'hyp': 0, 'ref': 11}, 'airport_name': {'cor': 0, 'hyp': 0, 'ref': 21}, 'connect': {'cor': 0, 'hyp': 0, 'ref': 6}, 'time': {'cor': 0, 'hyp': 2, 'ref': 0}, 'depart_date.today_relative': {'cor': 0, 'hyp': 0, 'ref': 9}, 'meal_description': {'cor': 0, 'hyp': 0, 'ref': 10}, 'arrive_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 2}, 'arrive_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 11}, 'airline_code': {'cor': 0, 'hyp': 0, 'ref': 34}, 'fromloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 17}, 'city_name': {'cor': 0, 'hyp': 0, 'ref': 57}, 'cost_relative': {'cor': 0, 'hyp': 0, 'ref': 37}, 'flight_mod': {'cor': 0, 'hyp': 0, 'ref': 24}, 'class_type': {'cor': 0, 'hyp': 0, 'ref': 24}, 'flight_time': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.country_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 3}, 'depart_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 3}, 'compartment': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 18}, 'transport_type': {'cor': 0, 'hyp': 0, 'ref': 10}, 'toloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 3}, 'aircraft_code': {'cor': 0, 'hyp': 0, 'ref': 33}, 'mod': {'cor': 0, 'hyp': 0, 'ref': 2}, 'state_name': {'cor': 0, 'hyp': 0, 'ref': 9}, 'day_name': {'cor': 0, 'hyp': 0, 'ref': 2}, 'meal_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'depart_time.period_mod': {'cor': 0, 'hyp': 0, 'ref': 5}, 'fromloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 5}, 'fromloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 23}, 'flight_days': {'cor': 0, 'hyp': 0, 'ref': 10}, 'fare_basis_code': {'cor': 0, 'hyp': 3, 'ref': 17}, 'depart_date.year': {'cor': 0, 'hyp': 0, 'ref': 3}, 'period_of_day': {'cor': 0, 'hyp': 0, 'ref': 4}, 'state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'airport_code': {'cor': 0, 'hyp': 0, 'ref': 9}, 'restriction_code': {'cor': 0, 'hyp': 0, 'ref': 4}, 'days_code': {'cor': 0, 'hyp': 1, 'ref': 1}, 'or': {'cor': 0, 'hyp': 0, 'ref': 3}, 'stoploc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'economy': {'cor': 0, 'hyp': 0, 'ref': 6}, 'fare_amount': {'cor': 0, 'hyp': 0, 'ref': 2}, 'booking_class': {'cor': 0, 'hyp': 0, 'ref': 1}, 'flight': {'cor': 0, 'hyp': 0, 'ref': 1}}\n",
      "Slot F1:  0.002099370188943317\n",
      "Intent Accuracy: 0.7077267637178052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "n_epochs = 10\n",
    "patience = 3\n",
    "losses_train = []\n",
    "losses_dev = []\n",
    "sampled_epochs = []\n",
    "best_f1 = 0\n",
    "from conll import evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_loop(data, optimizer, criterion_slots, criterion_intents, model, clip=5):\n",
    "    model.train()\n",
    "    loss_array = []\n",
    "    for sample in data:\n",
    "        optimizer.zero_grad() # Zeroing the gradient\n",
    "        slots, intent = model(sample['utterances'], sample['slots_len'])\n",
    "        loss_intent = criterion_intents(intent, sample['intents'])\n",
    "        loss_slot = criterion_slots(slots, sample['y_slots'])\n",
    "        loss = loss_intent + loss_slot # In joint training we sum the losses. \n",
    "                                       # Is there another way to do that?\n",
    "        loss_array.append(loss.item())\n",
    "        loss.backward() # Compute the gradient, deleting the computational graph\n",
    "        # clip the gradient to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  \n",
    "        optimizer.step() # Update the weights\n",
    "    return loss_array\n",
    "\n",
    "def eval_loop(data, criterion_slots, criterion_intents, model, lang):\n",
    "    model.eval()\n",
    "    loss_array = []\n",
    "    \n",
    "    ref_intents = []\n",
    "    hyp_intents = []\n",
    "    \n",
    "    ref_slots = []\n",
    "    hyp_slots = []\n",
    "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
    "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
    "        for sample in data:\n",
    "            slots, intents = model(sample['utterances'], sample['slots_len'])\n",
    "            loss_intent = criterion_intents(intents, sample['intents'])\n",
    "            loss_slot = criterion_slots(slots, sample['y_slots'])\n",
    "            loss = loss_intent + loss_slot \n",
    "            loss_array.append(loss.item())\n",
    "            # Intent inference\n",
    "            # Get the highest probable class\n",
    "            out_intents = [lang.id2intent[x] \n",
    "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
    "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
    "            ref_intents.extend(gt_intents)\n",
    "            hyp_intents.extend(out_intents)\n",
    "            \n",
    "            # Slot inference\n",
    "            output_slots = torch.argmax(slots, dim=1)\n",
    "            for id_seq, seq in enumerate(output_slots):\n",
    "                length = sample['slots_len'].tolist()[id_seq]\n",
    "                utt_ids = sample['utterance'][id_seq][:length].tolist()\n",
    "                gt_ids = sample['y_slots'][id_seq].tolist()\n",
    "                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n",
    "                utterance = [lang.id2word[elem] for elem in utt_ids]\n",
    "                to_decode = seq[:length].tolist()\n",
    "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
    "                tmp_seq = []\n",
    "                for id_el, elem in enumerate(to_decode):\n",
    "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]))\n",
    "                hyp_slots.append(tmp_seq)\n",
    "    try:            \n",
    "        results = evaluate(ref_slots, hyp_slots)\n",
    "    except Exception as ex:\n",
    "        # Sometimes the model predicts a class that is not in REF\n",
    "        print(\"Warning:\", ex)\n",
    "        ref_s = set([x[1] for x in ref_slots])\n",
    "        hyp_s = set([x[1] for x in hyp_slots])\n",
    "        print(hyp_s.difference(ref_s))\n",
    "        results = {\"total\":{\"f\":0}}\n",
    "        \n",
    "    report_intent = classification_report(ref_intents, hyp_intents, \n",
    "                                          zero_division=False, output_dict=True)\n",
    "    return results, report_intent, loss_array\n",
    "\n",
    "for x in tqdm(range(1,n_epochs)):\n",
    "    loss = train_loop(train_loader, optimizer, criterion_slots, \n",
    "                      criterion_intents, model, clip=clip)\n",
    "    if x % 1 == 0: # We check the performance every 5 epochs\n",
    "        sampled_epochs.append(x)\n",
    "        losses_train.append(np.asarray(loss).mean())\n",
    "        results_dev, intent_res, loss_dev = eval_loop(dev_loader, criterion_slots, \n",
    "                                                      criterion_intents, model, lang)\n",
    "        losses_dev.append(np.asarray(loss_dev).mean())\n",
    "        \n",
    "        f1 = results_dev['total']['f']\n",
    "        # For decreasing the patience you can also use the average between slot f1 and intent accuracy\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            # Here you should save the model\n",
    "            patience = 3\n",
    "        else:\n",
    "            patience -= 1\n",
    "        if patience <= 0: # Early stopping with patience\n",
    "            break # Not nice but it keeps the code clean\n",
    "\n",
    "results_test, intent_test, _ = eval_loop(test_loader, criterion_slots, \n",
    "                                         criterion_intents, model, lang)    \n",
    "print('Slot F1: ', results_test['total']['f'])\n",
    "print('Intent Accuracy:', intent_test['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc39e9c",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "To save the model you have to save:\n",
    "- The weights of the model\n",
    "- The computed vocabularies (w2id, slot2id, intent2id)\n",
    "- The optimizer (optionally, only if you want to continue with the training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = os.path.join(\"bin\", model_name)\n",
    "# saving_object = {\"epoch\": x, \n",
    "#                  \"model\": model.state_dict(), \n",
    "#                  \"optimizer\": optimizer.state_dict(), \n",
    "#                  \"w2id\": w2id, \n",
    "#                  \"slot2id\": slot2id, \n",
    "#                  \"intent2id\": intent2id}\n",
    "# torch.save(saving_object, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1466a",
   "metadata": {},
   "source": [
    "### Plot of the train and valid losses\n",
    "One of the techniques for debugging a neural network is to check the plot of the loss. If the loss goes smoothly down then the network works correctly, otherwise a deeper analysis is needed. Furthermore, this plot can be useful for deciding the learning rate and the optimizer algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1211aab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num = 3, figsize=(8, 5)).patch.set_facecolor('white')\n",
    "plt.title('Train and Dev Losses')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.plot(sampled_epochs, losses_train, label='Train loss')\n",
    "plt.plot(sampled_epochs, losses_dev, label='Dev loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420df73c",
   "metadata": {},
   "source": [
    "### Multiple runs\n",
    "To have reliable results on small corpora we have to train and test the model from scratch for several times. At the end, we average the results and we compute the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f08d0445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cor': 3, 'hyp': 19, 'ref': 1692}\n",
      "{'fromloc.city_name': {'cor': 0, 'hyp': 0, 'ref': 424}, 'toloc.city_name': {'cor': 0, 'hyp': 9, 'ref': 444}, 'stoploc.city_name': {'cor': 0, 'hyp': 0, 'ref': 27}, 'flight_time': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 91}, 'depart_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_date.day_number': {'cor': 1, 'hyp': 1, 'ref': 43}, 'depart_time.period_mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 60}, 'or': {'cor': 0, 'hyp': 0, 'ref': 6}, 'arrive_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 20}, 'arrive_time.time': {'cor': 0, 'hyp': 0, 'ref': 20}, 'flight_stop': {'cor': 0, 'hyp': 0, 'ref': 14}, 'meal': {'cor': 0, 'hyp': 0, 'ref': 9}, 'airline_name': {'cor': 2, 'hyp': 3, 'ref': 70}, 'flight_number': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_time.time': {'cor': 0, 'hyp': 0, 'ref': 37}, 'flight_mod': {'cor': 0, 'hyp': 0, 'ref': 29}, 'return_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 2}, 'cost_relative': {'cor': 0, 'hyp': 0, 'ref': 41}, 'round_trip': {'cor': 0, 'hyp': 0, 'ref': 38}, 'class_type': {'cor': 0, 'hyp': 3, 'ref': 20}, 'depart_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 35}, 'airline_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'meal_description': {'cor': 0, 'hyp': 0, 'ref': 6}, 'fromloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 6}, 'toloc.state_name': {'cor': 0, 'hyp': 1, 'ref': 10}, 'toloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'transport_type': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 11}, 'depart_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 9}, 'economy': {'cor': 0, 'hyp': 0, 'ref': 5}, 'fare_basis_code': {'cor': 0, 'hyp': 0, 'ref': 7}, 'city_name': {'cor': 0, 'hyp': 0, 'ref': 22}, 'restriction_code': {'cor': 0, 'hyp': 0, 'ref': 3}, 'airport_code': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 7}, 'fare_amount': {'cor': 0, 'hyp': 0, 'ref': 8}, 'arrive_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'arrive_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'airport_name': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'day_name': {'cor': 0, 'hyp': 0, 'ref': 3}, 'month_name': {'cor': 0, 'hyp': 0, 'ref': 2}, 'day_number': {'cor': 0, 'hyp': 0, 'ref': 2}, 'arrive_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'connect': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'toloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'depart_date.today_relative': {'cor': 0, 'hyp': 0, 'ref': 7}, 'days_code': {'cor': 0, 'hyp': 2, 'ref': 2}, 'fromloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'aircraft_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'stoploc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'depart_date.year': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 1}, 'flight_days': {'cor': 0, 'hyp': 0, 'ref': 1}, 'stoploc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb Cell 43\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#X60sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m best_f1 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#X60sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,n_epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#X60sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     loss \u001b[39m=\u001b[39m train_loop(train_loader, optimizer, criterion_slots, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#X60sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                       criterion_intents, model)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#X60sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mif\u001b[39;00m x \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#X60sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         sampled_epochs\u001b[39m.\u001b[39mappend(x)\n",
      "\u001b[1;32m/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb Cell 43\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#X60sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                                \u001b[39m# Is there another way to do that?\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#X60sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss_array\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#X60sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward() \u001b[39m# Compute the gradient, deleting the computational graph\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#X60sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# clip the gradient to avoid exploding gradients\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#X60sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), clip)  \n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hid_size = 200\n",
    "emb_size = 300\n",
    "\n",
    "lr = 0.0001 # learning rate\n",
    "clip = 5 # Clip the gradient\n",
    "\n",
    "\n",
    "out_slot = len(lang.slot2id)\n",
    "out_int = len(lang.intent2id)\n",
    "vocab_len = len(lang.word2id)\n",
    "\n",
    "n_epochs = 200\n",
    "runs = 5\n",
    "\n",
    "slot_f1s, intent_acc = [], []\n",
    "for x in tqdm(range(0, runs)):\n",
    "    model = ModelIAS(hid_size, out_slot, out_int, emb_size, \n",
    "                     vocab_len, pad_index=PAD_TOKEN).to(device)\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "    criterion_intents = nn.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "    patience = 3\n",
    "    losses_train = []\n",
    "    losses_dev = []\n",
    "    sampled_epochs = []\n",
    "    best_f1 = 0\n",
    "    for x in range(1,n_epochs):\n",
    "        loss = train_loop(train_loader, optimizer, criterion_slots, \n",
    "                          criterion_intents, model)\n",
    "        if x % 5 == 0:\n",
    "            sampled_epochs.append(x)\n",
    "            losses_train.append(np.asarray(loss).mean())\n",
    "            results_dev, intent_res, loss_dev = eval_loop(dev_loader, criterion_slots, \n",
    "                                                          criterion_intents, model, lang)\n",
    "            losses_dev.append(np.asarray(loss_dev).mean())\n",
    "            f1 = results_dev['total']['f']\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "            else:\n",
    "                patience -= 1\n",
    "            if patience <= 0: # Early stopping with patient\n",
    "                break # Not nice but it keeps the code clean\n",
    "\n",
    "    results_test, intent_test, _ = eval_loop(test_loader, criterion_slots, \n",
    "                                             criterion_intents, model, lang)\n",
    "    intent_acc.append(intent_test['accuracy'])\n",
    "    slot_f1s.append(results_test['total']['f'])\n",
    "slot_f1s = np.asarray(slot_f1s)\n",
    "intent_acc = np.asarray(intent_acc)\n",
    "print('Slot F1', round(slot_f1s.mean(),3), '+-', round(slot_f1s.std(),3))\n",
    "print('Intent Acc', round(intent_acc.mean(), 3), '+-', round(slot_f1s.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe4565d",
   "metadata": {},
   "source": [
    " ![](https://huggingface.co/front/assets/huggingface_logo-noborder.svg)\n",
    "# Hugging Face\n",
    "Hugging Face is a library that allows you to use pretrained models in an easy way. This means that you do not need to implement an architecture and train it from scratch. Hugging Face is based on a community where people share trained models and code.\n",
    "<br/><br/>\n",
    "In Hugging Face there are many different models (https://huggingface.co/models) that you can import and each of them has its own input and output shapes. However, Transformer-based models are usually composed of two parts: \n",
    "- **Tokenizer**\n",
    "- **Architecture/Pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b01cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0]]),\n",
      " 'input_ids': tensor([[  101,  1045,  2387,  1037,  2158,  2007,  1037, 12772,   102],\n",
      "        [  101,  2732, 19980,  2001,  2182,   102,     0,     0,     0],\n",
      "        [  101,  1045,  2134,  1005,  1056,   102,     0,     0,     0]]),\n",
      " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# BERT model script from: huggingface.co\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from pprint import pprint\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") # Download the tokenizer\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\") # Download the model\n",
    "\n",
    "inputs = tokenizer([\"I saw a man with a telescope\", \"StarLord was here\",  \"I didn't\"], return_tensors=\"pt\", padding=True)\n",
    "pprint(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b72e045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tell',\n",
       " 'me',\n",
       " 'about',\n",
       " 'flights',\n",
       " 'from',\n",
       " 'salt',\n",
       " 'lake',\n",
       " 'city',\n",
       " 'to',\n",
       " 'st.',\n",
       " 'petersburg']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for id in dev_dataset[3]['utterance'].tolist():\n",
    "    a.append(lang.id2word[id])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04ff455c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2358, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = tokenizer(['st.'])\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"\"], return_tensors=\"pt\", padding=True)\n",
    "pprint(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a5c31e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'st', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens((st['input_ids'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "86677c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'what', \"'\", 's', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "st = tokenizer([\"what's\"])\n",
    "print(tokenizer.convert_ids_to_tokens((st['input_ids'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6260ab5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2304, 6277, 102]], 'token_type_ids': [[0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['blackboard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0da38034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in keys\n"
     ]
    }
   ],
   "source": [
    "if 'blackboard' not in tokenizer.vocab:\n",
    "    print('not in keys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36f26671",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9139e1c",
   "metadata": {},
   "source": [
    "##  Byte pair encoding\n",
    "The tricky part of using Transformer-based model is the tokenizer which is based on byte pair encoding algorithm. Indeed, the **tokenizers** used by Transformer-based models are different from those we have seen in the lab. While for instance Spacy's tokenizer is rule-based and splits the text looking at the punctuation, the goal of Transformer tokenizers is to reduce the vocabulary length by splitting words into subwords. A thoroughly explanation of such these tokenizers can be found here: https://huggingface.co/docs/transformers/tokenizer_summary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b60584d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,  1045,  2387,  1037,  2158,  2007,  1037, 12772,   102])\n",
      "['[CLS]', 'i', 'saw', 'a', 'man', 'with', 'a', 'telescope', '[SEP]']\n",
      "['[CLS]', 'star', '##lord', 'was', 'here', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"][0])\n",
    "print(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0]))\n",
    "print(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "215505b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'superb', '##ig', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "a = \"superbig\"\n",
    "tokenizer.convert_ids_to_tokens(tokenizer(a)['input_ids'])\n",
    "for e in a.split():\n",
    "    print(tokenizer.convert_ids_to_tokens(tokenizer(e)['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2dcc1f",
   "metadata": {},
   "source": [
    "# Mandatory Exam Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2fad3c",
   "metadata": {},
   "source": [
    "## Part 1 (4 points)\n",
    "As for LM project, you have to apply these two modifications incrementally. Also in this case you may have to play with the hyperparameters and optimizers to improve the performance. \n",
    "\n",
    "Modify the baseline architecture Model IAS by:\n",
    "- Adding bidirectionality\n",
    "- Adding dropout layer\n",
    "\n",
    "**Intent classification**: accuracy <br>\n",
    "**Slot filling**: F1 score with conll\n",
    "\n",
    "***Dataset to use: ATIS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c280e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 exercise:\n",
    "# Adding bidirectionality and dropout layer\n",
    "\n",
    "class ModelIAS(nn.Module):\n",
    "\n",
    "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=1, pad_index=0):\n",
    "        super(ModelIAS, self).__init__()\n",
    "        # hid_size = Hidden size\n",
    "        # out_slot = number of slots (output size for slot filling)\n",
    "        # out_int = number of intents (output size for intent class)\n",
    "        # emb_size = word embedding size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_len, emb_size, padding_idx=pad_index)\n",
    "        \n",
    "        # Add biodirectionality to the LSTM layer. As a result the size of the hidden states is doubled\n",
    "        self.utt_encoder = nn.LSTM(emb_size, hid_size, n_layer, bidirectional=True, batch_first=True)\n",
    "        self.slot_out = nn.Linear(hid_size * 2, out_slot)\n",
    "        self.intent_out = nn.Linear(hid_size * 2, out_int)\n",
    "        # Dropout layer How/Where do we apply it?\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, utterance, seq_lengths):\n",
    "        # utterance.size() = batch_size X seq_len\n",
    "        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
    "        \n",
    "        utt_emb = self.dropout(utt_emb) # we can use dropout after the embedding layer\n",
    "\n",
    "        # pack_padded_sequence avoid computation over pad tokens reducing the computational cost\n",
    "        #.cpu().numpy() converts the seq_lengths tensor to a NumPy array and moves it to the CPU memory\n",
    "        # This is done because pack_padded_sequence expects the sequence lengths to be provided as a CPU-based NumPy array.\n",
    "        packed_input = pack_padded_sequence(utt_emb, seq_lengths.cpu().numpy(), batch_first=True)\n",
    "        # Process the batch\n",
    "        packed_output, (last_hidden, cell) = self.utt_encoder(packed_input) \n",
    "\n",
    "        # Unpack the sequence\n",
    "        utt_encoded, input_sizes = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        utt_emb = self.dropout(utt_encoded) # we can use dropout after the LSTM layer too!\n",
    "        \n",
    "        # Get the last [forward and backward] hidden states\n",
    "        # Clarification: The last hidden state, obtained using last_hidden[-1, :, :], represents\n",
    "        # the hidden state corresponding to the last time step of the sequences in the batch.\n",
    "        # we concatenate the forward and backward hidden states along the hidden size dimension (dim=1)\n",
    "        # last_hidden = last_hidden[-1,:,:] # without bidirectionality\n",
    "        last_hidden = torch.cat((last_hidden[-2, :, :],  # last hidden state from the forward pass\n",
    "                                 last_hidden[-1, :, :]), # last hidden state from the backward pass\n",
    "                                 dim=1) # sequence dimension\n",
    "        \n",
    "        # Is this another possible way to get the last hiddent state? (Why?)\n",
    "        # utt_encoded.permute(1,0,2)[-1]\n",
    "        \n",
    "        # Compute slot logits\n",
    "        slots = self.slot_out(utt_encoded)\n",
    "        # Compute intent logits\n",
    "        intent = self.intent_out(last_hidden)\n",
    "        \n",
    "        # Slot size: batch_size, seq_len, classes \n",
    "        slots = slots.permute(0,2,1) # We need this for computing the loss\n",
    "        # Slot size: batch_size, classes, seq_len\n",
    "        return slots, intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c92efa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "hid_size = 200\n",
    "emb_size = 300\n",
    "\n",
    "lr = 0.0001 # learning rate\n",
    "clip = 5 # Clip the gradient\n",
    "\n",
    "out_slot = len(lang.slot2id)\n",
    "out_int = len(lang.intent2id)\n",
    "vocab_len = len(lang.word2id)\n",
    "\n",
    "model = ModelIAS(hid_size, out_slot, out_int, emb_size, vocab_len, pad_index=PAD_TOKEN).to(device)\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "criterion_intents = nn.CrossEntropyLoss() # Because we do not have the pad token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db8d33da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/199 [00:03<02:22,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cor': 143, 'hyp': 618, 'ref': 1692}\n",
      "{'fromloc.city_name': {'cor': 0, 'hyp': 0, 'ref': 424}, 'toloc.city_name': {'cor': 143, 'hyp': 618, 'ref': 444}, 'stoploc.city_name': {'cor': 0, 'hyp': 0, 'ref': 27}, 'flight_time': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 91}, 'depart_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_time.period_mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 60}, 'or': {'cor': 0, 'hyp': 0, 'ref': 6}, 'arrive_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 20}, 'arrive_time.time': {'cor': 0, 'hyp': 0, 'ref': 20}, 'flight_stop': {'cor': 0, 'hyp': 0, 'ref': 14}, 'meal': {'cor': 0, 'hyp': 0, 'ref': 9}, 'airline_name': {'cor': 0, 'hyp': 0, 'ref': 70}, 'flight_number': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_time.time': {'cor': 0, 'hyp': 0, 'ref': 37}, 'flight_mod': {'cor': 0, 'hyp': 0, 'ref': 29}, 'return_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 2}, 'cost_relative': {'cor': 0, 'hyp': 0, 'ref': 41}, 'round_trip': {'cor': 0, 'hyp': 0, 'ref': 38}, 'class_type': {'cor': 0, 'hyp': 0, 'ref': 20}, 'depart_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 35}, 'airline_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'meal_description': {'cor': 0, 'hyp': 0, 'ref': 6}, 'fromloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 6}, 'toloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 10}, 'toloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'transport_type': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 11}, 'depart_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 9}, 'economy': {'cor': 0, 'hyp': 0, 'ref': 5}, 'fare_basis_code': {'cor': 0, 'hyp': 0, 'ref': 7}, 'city_name': {'cor': 0, 'hyp': 0, 'ref': 22}, 'restriction_code': {'cor': 0, 'hyp': 0, 'ref': 3}, 'airport_code': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 7}, 'fare_amount': {'cor': 0, 'hyp': 0, 'ref': 8}, 'arrive_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'arrive_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'airport_name': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'day_name': {'cor': 0, 'hyp': 0, 'ref': 3}, 'month_name': {'cor': 0, 'hyp': 0, 'ref': 2}, 'day_number': {'cor': 0, 'hyp': 0, 'ref': 2}, 'arrive_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'connect': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'toloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'depart_date.today_relative': {'cor': 0, 'hyp': 0, 'ref': 7}, 'days_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'fromloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'aircraft_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'stoploc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'depart_date.year': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 1}, 'flight_days': {'cor': 0, 'hyp': 0, 'ref': 1}, 'stoploc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/199 [00:07<02:19,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cor': 591, 'hyp': 1151, 'ref': 1692}\n",
      "{'fromloc.city_name': {'cor': 271, 'hyp': 354, 'ref': 424}, 'toloc.city_name': {'cor': 312, 'hyp': 781, 'ref': 444}, 'stoploc.city_name': {'cor': 0, 'hyp': 0, 'ref': 27}, 'flight_time': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_date.day_name': {'cor': 8, 'hyp': 9, 'ref': 91}, 'depart_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 43}, 'depart_time.period_mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.period_of_day': {'cor': 0, 'hyp': 1, 'ref': 60}, 'or': {'cor': 0, 'hyp': 0, 'ref': 6}, 'arrive_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 20}, 'arrive_time.time': {'cor': 0, 'hyp': 0, 'ref': 20}, 'flight_stop': {'cor': 0, 'hyp': 0, 'ref': 14}, 'meal': {'cor': 0, 'hyp': 0, 'ref': 9}, 'airline_name': {'cor': 0, 'hyp': 6, 'ref': 70}, 'flight_number': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_time.time': {'cor': 0, 'hyp': 0, 'ref': 37}, 'flight_mod': {'cor': 0, 'hyp': 0, 'ref': 29}, 'return_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 2}, 'cost_relative': {'cor': 0, 'hyp': 0, 'ref': 41}, 'round_trip': {'cor': 0, 'hyp': 0, 'ref': 38}, 'class_type': {'cor': 0, 'hyp': 0, 'ref': 20}, 'depart_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 35}, 'airline_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'meal_description': {'cor': 0, 'hyp': 0, 'ref': 6}, 'fromloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 6}, 'toloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 10}, 'toloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'transport_type': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 11}, 'depart_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 9}, 'economy': {'cor': 0, 'hyp': 0, 'ref': 5}, 'fare_basis_code': {'cor': 0, 'hyp': 0, 'ref': 7}, 'city_name': {'cor': 0, 'hyp': 0, 'ref': 22}, 'restriction_code': {'cor': 0, 'hyp': 0, 'ref': 3}, 'airport_code': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 7}, 'fare_amount': {'cor': 0, 'hyp': 0, 'ref': 8}, 'arrive_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'arrive_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'airport_name': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'day_name': {'cor': 0, 'hyp': 0, 'ref': 3}, 'month_name': {'cor': 0, 'hyp': 0, 'ref': 2}, 'day_number': {'cor': 0, 'hyp': 0, 'ref': 2}, 'arrive_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'connect': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'toloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'depart_date.today_relative': {'cor': 0, 'hyp': 0, 'ref': 7}, 'days_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'fromloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'aircraft_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'stoploc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'depart_date.year': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 1}, 'flight_days': {'cor': 0, 'hyp': 0, 'ref': 1}, 'stoploc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/199 [00:11<02:12,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cor': 973, 'hyp': 1387, 'ref': 1692}\n",
      "{'fromloc.city_name': {'cor': 386, 'hyp': 456, 'ref': 424}, 'toloc.city_name': {'cor': 370, 'hyp': 599, 'ref': 444}, 'stoploc.city_name': {'cor': 0, 'hyp': 0, 'ref': 27}, 'flight_time': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_date.day_name': {'cor': 61, 'hyp': 82, 'ref': 91}, 'depart_date.month_name': {'cor': 7, 'hyp': 7, 'ref': 43}, 'depart_date.day_number': {'cor': 0, 'hyp': 7, 'ref': 43}, 'depart_time.period_mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.period_of_day': {'cor': 18, 'hyp': 24, 'ref': 60}, 'or': {'cor': 0, 'hyp': 0, 'ref': 6}, 'arrive_time.time_relative': {'cor': 0, 'hyp': 0, 'ref': 20}, 'arrive_time.time': {'cor': 0, 'hyp': 0, 'ref': 20}, 'flight_stop': {'cor': 0, 'hyp': 0, 'ref': 14}, 'meal': {'cor': 0, 'hyp': 0, 'ref': 9}, 'airline_name': {'cor': 25, 'hyp': 47, 'ref': 70}, 'flight_number': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_time.time': {'cor': 8, 'hyp': 45, 'ref': 37}, 'flight_mod': {'cor': 11, 'hyp': 11, 'ref': 29}, 'return_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 2}, 'depart_time.time_relative': {'cor': 33, 'hyp': 42, 'ref': 35}, 'cost_relative': {'cor': 15, 'hyp': 15, 'ref': 41}, 'round_trip': {'cor': 22, 'hyp': 26, 'ref': 38}, 'class_type': {'cor': 7, 'hyp': 12, 'ref': 20}, 'airline_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'meal_description': {'cor': 0, 'hyp': 0, 'ref': 6}, 'fromloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 6}, 'toloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 10}, 'toloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'transport_type': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 11}, 'depart_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 9}, 'economy': {'cor': 0, 'hyp': 0, 'ref': 5}, 'fare_basis_code': {'cor': 0, 'hyp': 0, 'ref': 7}, 'city_name': {'cor': 10, 'hyp': 14, 'ref': 22}, 'restriction_code': {'cor': 0, 'hyp': 0, 'ref': 3}, 'airport_code': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 7}, 'fare_amount': {'cor': 0, 'hyp': 0, 'ref': 8}, 'arrive_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'arrive_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'airport_name': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'day_name': {'cor': 0, 'hyp': 0, 'ref': 3}, 'month_name': {'cor': 0, 'hyp': 0, 'ref': 2}, 'day_number': {'cor': 0, 'hyp': 0, 'ref': 2}, 'arrive_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'connect': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'toloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'depart_date.today_relative': {'cor': 0, 'hyp': 0, 'ref': 7}, 'days_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'fromloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'aircraft_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'stoploc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'depart_date.year': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 1}, 'flight_days': {'cor': 0, 'hyp': 0, 'ref': 1}, 'stoploc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/199 [00:14<02:19,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cor': 1219, 'hyp': 1497, 'ref': 1692}\n",
      "{'fromloc.city_name': {'cor': 408, 'hyp': 447, 'ref': 424}, 'toloc.city_name': {'cor': 410, 'hyp': 508, 'ref': 444}, 'stoploc.city_name': {'cor': 0, 'hyp': 0, 'ref': 27}, 'flight_time': {'cor': 0, 'hyp': 0, 'ref': 7}, 'depart_date.day_name': {'cor': 78, 'hyp': 98, 'ref': 91}, 'depart_date.month_name': {'cor': 23, 'hyp': 27, 'ref': 43}, 'depart_date.day_number': {'cor': 11, 'hyp': 25, 'ref': 43}, 'depart_time.period_mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.period_of_day': {'cor': 48, 'hyp': 55, 'ref': 60}, 'or': {'cor': 0, 'hyp': 0, 'ref': 6}, 'arrive_time.time_relative': {'cor': 5, 'hyp': 5, 'ref': 20}, 'arrive_time.time': {'cor': 0, 'hyp': 0, 'ref': 20}, 'depart_time.time': {'cor': 30, 'hyp': 66, 'ref': 37}, 'flight_stop': {'cor': 8, 'hyp': 8, 'ref': 14}, 'meal': {'cor': 0, 'hyp': 0, 'ref': 9}, 'airline_name': {'cor': 49, 'hyp': 67, 'ref': 70}, 'flight_number': {'cor': 0, 'hyp': 0, 'ref': 7}, 'flight_mod': {'cor': 19, 'hyp': 20, 'ref': 29}, 'return_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 2}, 'depart_time.time_relative': {'cor': 33, 'hyp': 41, 'ref': 35}, 'cost_relative': {'cor': 24, 'hyp': 27, 'ref': 41}, 'round_trip': {'cor': 35, 'hyp': 39, 'ref': 38}, 'class_type': {'cor': 13, 'hyp': 19, 'ref': 20}, 'airline_code': {'cor': 0, 'hyp': 0, 'ref': 12}, 'meal_description': {'cor': 0, 'hyp': 0, 'ref': 6}, 'fromloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 6}, 'toloc.state_name': {'cor': 0, 'hyp': 0, 'ref': 10}, 'toloc.state_code': {'cor': 9, 'hyp': 10, 'ref': 12}, 'transport_type': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.airport_name': {'cor': 0, 'hyp': 1, 'ref': 11}, 'depart_date.date_relative': {'cor': 0, 'hyp': 0, 'ref': 9}, 'economy': {'cor': 0, 'hyp': 0, 'ref': 5}, 'fare_basis_code': {'cor': 0, 'hyp': 0, 'ref': 7}, 'city_name': {'cor': 16, 'hyp': 31, 'ref': 22}, 'restriction_code': {'cor': 0, 'hyp': 0, 'ref': 3}, 'airport_code': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_name': {'cor': 0, 'hyp': 0, 'ref': 7}, 'fare_amount': {'cor': 0, 'hyp': 3, 'ref': 8}, 'arrive_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 5}, 'arrive_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'arrive_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'airport_name': {'cor': 0, 'hyp': 0, 'ref': 4}, 'fromloc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'day_name': {'cor': 0, 'hyp': 0, 'ref': 3}, 'month_name': {'cor': 0, 'hyp': 0, 'ref': 2}, 'day_number': {'cor': 0, 'hyp': 0, 'ref': 2}, 'arrive_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.start_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'depart_time.end_time': {'cor': 0, 'hyp': 0, 'ref': 4}, 'connect': {'cor': 0, 'hyp': 0, 'ref': 1}, 'toloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'mod': {'cor': 0, 'hyp': 0, 'ref': 4}, 'toloc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 5}, 'depart_date.today_relative': {'cor': 0, 'hyp': 0, 'ref': 7}, 'days_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'fromloc.airport_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'aircraft_code': {'cor': 0, 'hyp': 0, 'ref': 2}, 'stoploc.state_code': {'cor': 0, 'hyp': 0, 'ref': 1}, 'depart_date.year': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_time.period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.month_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'return_date.day_number': {'cor': 0, 'hyp': 0, 'ref': 1}, 'flight_days': {'cor': 0, 'hyp': 0, 'ref': 1}, 'stoploc.airport_name': {'cor': 0, 'hyp': 0, 'ref': 1}, 'period_of_day': {'cor': 0, 'hyp': 0, 'ref': 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/199 [00:18<02:11,  1.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb Cell 54\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y104sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m best_f1 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y104sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,n_epochs)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y104sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     loss \u001b[39m=\u001b[39m train_loop(train_loader, optimizer, criterion_slots, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y104sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                       criterion_intents, model, clip\u001b[39m=\u001b[39;49mclip)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y104sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mif\u001b[39;00m x \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39m# We check the performance every 5 epochs\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y104sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         sampled_epochs\u001b[39m.\u001b[39mappend(x)\n",
      "\u001b[1;32m/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb Cell 54\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y104sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                                \u001b[39m# Is there another way to do that?\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y104sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss_array\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y104sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward() \u001b[39m# Compute the gradient, deleting the computational graph\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y104sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# clip the gradient to avoid exploding gradients\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y104sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), clip)  \n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "n_epochs = 200\n",
    "patience = 3\n",
    "losses_train = []\n",
    "losses_dev = []\n",
    "sampled_epochs = []\n",
    "best_f1 = 0\n",
    "for x in tqdm(range(1,n_epochs)):\n",
    "    loss = train_loop(train_loader, optimizer, criterion_slots, \n",
    "                      criterion_intents, model, clip=clip)\n",
    "    if x % 5 == 0: # We check the performance every 5 epochs\n",
    "        sampled_epochs.append(x)\n",
    "        losses_train.append(np.asarray(loss).mean())\n",
    "        results_dev, intent_res, loss_dev = eval_loop(dev_loader, criterion_slots, \n",
    "                                                      criterion_intents, model, lang)\n",
    "        losses_dev.append(np.asarray(loss_dev).mean())\n",
    "        \n",
    "        f1 = results_dev['total']['f']\n",
    "        # For decreasing the patience you can also use the average between slot f1 and intent accuracy\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            # Here you should save the model\n",
    "            patience = 3\n",
    "        else:\n",
    "            patience -= 1\n",
    "        if patience <= 0: # Early stopping with patience\n",
    "            break # Not nice but it keeps the code clean\n",
    "\n",
    "results_test, intent_test, _ = eval_loop(test_loader, criterion_slots, \n",
    "                                         criterion_intents, model, lang)    \n",
    "print('Slot F1: ', results_test['total']['f'])\n",
    "print('Intent Accuracy:', intent_test['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5b259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_size = 200\n",
    "emb_size = 300\n",
    "\n",
    "lr = 0.0001 # learning rate\n",
    "clip = 5 # Clip the gradient\n",
    "\n",
    "\n",
    "out_slot = len(lang.slot2id)\n",
    "out_int = len(lang.intent2id)\n",
    "vocab_len = len(lang.word2id)\n",
    "\n",
    "n_epochs = 200\n",
    "runs = 5\n",
    "\n",
    "slot_f1s, intent_acc = [], []\n",
    "for x in tqdm(range(0, runs)):\n",
    "    model = ModelIAS(hid_size, out_slot, out_int, emb_size, \n",
    "                     vocab_len, pad_index=PAD_TOKEN).to(device)\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "    criterion_intents = nn.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "    patience = 3\n",
    "    losses_train = []\n",
    "    losses_dev = []\n",
    "    sampled_epochs = []\n",
    "    best_f1 = 0\n",
    "    for x in range(1,n_epochs):\n",
    "        loss = train_loop(train_loader, optimizer, criterion_slots, \n",
    "                          criterion_intents, model)\n",
    "        if x % 5 == 0:\n",
    "            sampled_epochs.append(x)\n",
    "            losses_train.append(np.asarray(loss).mean())\n",
    "            results_dev, intent_res, loss_dev = eval_loop(dev_loader, criterion_slots, \n",
    "                                                          criterion_intents, model, lang)\n",
    "            losses_dev.append(np.asarray(loss_dev).mean())\n",
    "            f1 = results_dev['total']['f']\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "            else:\n",
    "                patience -= 1\n",
    "            if patience <= 0: # Early stopping with patient\n",
    "                break # Not nice but it keeps the code clean\n",
    "\n",
    "    results_test, intent_test, _ = eval_loop(test_loader, criterion_slots, \n",
    "                                             criterion_intents, model, lang)\n",
    "    intent_acc.append(intent_test['accuracy'])\n",
    "    slot_f1s.append(results_test['total']['f'])\n",
    "slot_f1s = np.asarray(slot_f1s)\n",
    "intent_acc = np.asarray(intent_acc)\n",
    "print('Slot F1', round(slot_f1s.mean(),3), '+-', round(slot_f1s.std(),3))\n",
    "print('Intent Acc', round(intent_acc.mean(), 3), '+-', round(slot_f1s.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30eb2ce-9952-4127-b258-3d372f452c2b",
   "metadata": {},
   "source": [
    "## Part 2 (11 points)\n",
    "\n",
    "Adapt the code to fine-tune a pre-trained BERT model using a multi-task learning setting on intent classification and slot filling. \n",
    "You can refer to this paper to have a better understanding of how to implement this: https://arxiv.org/abs/1902.10909. In this, one of the challenges of this is to handle the sub-tokenization issue.\n",
    "\n",
    "*Note*: The fine-tuning process is to further train on a specific task/s a model that has been pre-trained on a different (potentially unrelated) task/s.\n",
    "\n",
    "\n",
    "The models that you can experiment with are [*BERT-base* or *BERT-large*](https://huggingface.co/google-bert/bert-base-uncased). \n",
    "\n",
    "**Intent classification**: accuracy <br>\n",
    "**Slot filling**: F1 score with conll\n",
    "\n",
    "***Dataset to use: ATIS***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b030c94",
   "metadata": {},
   "source": [
    "Start with some boiler plate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1af4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5dd2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "class BertIntentsAndSlots(data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch dataset class for intent classification and slot filling tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Mandatory methods are __init__, __len__ and __getitem__\n",
    "    def __init__(self, dataset, lang, unk='unk'):\n",
    "        \"\"\"\n",
    "        Initialize the dataset by mapping utterances, slots, and intents to integer IDs.\n",
    "\n",
    "        :param dataset: List of dictionaries, each containing 'utterance', 'slots', and 'intent'.\n",
    "        :param lang: Language object containing mapping information.\n",
    "        :param unk: Unknown token (default is 'unk').\n",
    "        \"\"\"\n",
    "\n",
    "        # Setting based on the current model type\n",
    "        # cls_token = tokenizer.cls_token\n",
    "        # sep_token = tokenizer.sep_token\n",
    "        # unk_token = tokenizer.unk_token\n",
    "        # pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "        self.utterances = []\n",
    "        self.intents = []\n",
    "        self.slots = []\n",
    "        \n",
    "        # Map utterances, slots, and intents to integer IDs\n",
    "        for x in dataset:\n",
    "            self.utterances.append(x['utterance'])\n",
    "            self.slots.append(x['slots'])\n",
    "            self.intents.append(x['intent'])\n",
    "        \n",
    "        self.slot_ids = self.mapping_seq(self.slots, lang.slot2id)\n",
    "        self.intent_ids = self.mapping_lab(self.intents, lang.intent2id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.utterances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return the dictionary for the example at index idx.\n",
    "\n",
    "        :param idx: Index of the example to retrieve.\n",
    "        :return: Dictionary containing 'utterance', 'slots', and 'intent' as integer IDs.\n",
    "        \"\"\"\n",
    "        utt = self.utterances[idx]\n",
    "        slots = self.slot_ids[idx]\n",
    "\n",
    "        intent = self.intent_ids[idx]\n",
    "\n",
    "        utt_inputs = tokenizer(utt, \n",
    "                               return_tensors=\"pt\", \n",
    "                            #    padding=True,\n",
    "                            #    max_length=200,\n",
    "                            #    pad_to_max_length=True,\n",
    "                               return_token_type_ids=True)\n",
    "                \n",
    "        ids = utt_inputs['input_ids']\n",
    "        mask = utt_inputs['attention_mask']\n",
    "        token_type_ids = utt_inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'slots' : torch.tensor(slots, dtype=torch.long), #.squeeze(), # unsqueeze so that we add an extra dim so that we can take .shape[1] in merge function\n",
    "            'intent': intent\n",
    "        }\n",
    "    \n",
    "    def mapping_lab(self, data, mapper):\n",
    "        \"\"\"\n",
    "        Map a list of labels to integer IDs, using the unknown token ID if not found in mapper.\n",
    "\n",
    "        :param data: List of labels.\n",
    "        :param mapper: Mapper dictionary.\n",
    "        :return: List of integer IDs.\n",
    "        \"\"\"\n",
    "        return [mapper[x] if x in mapper else mapper[self.unk] for x in data]\n",
    "    \n",
    "    def mapping_seq(self, data, mapper): # Map sequences to number\n",
    "        \"\"\"\n",
    "        Map a list of sequences to integer IDs, tokenizing each sequence.\n",
    "\n",
    "        :param data: List of sequences.\n",
    "        :param mapper: Mapper dictionary.\n",
    "        :return: List of tokenized and mapped sequences.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        # print(data)\n",
    "        # print(100*\"y\")\n",
    "        # print(self.utterances)\n",
    "        for seq, utt in zip(data, self.utterances):\n",
    "            tmp_seq = []\n",
    "            # example of slot: print(seq)= O O O O O O O O B-fromloc.city_name O B-toloc.city_name\n",
    "            for x, w in zip(seq.split(), utt.split()):\n",
    "                tokenized_word = tokenizer(w)['input_ids'][1:-1] # don't take the [CLS] and [SEP] tokens\n",
    "                # if len(tokenized_word) > 1:\n",
    "                #     print(tokenized_word, tokenizer.convert_ids_to_tokens(tokenized_word))\n",
    "                if x in mapper:\n",
    "                    tmp_seq.extend([mapper[x]] + [PAD_TOKEN]*(len(tokenized_word)-1)) # Example: [ [ID][PAD][PAD][PAD] ]\n",
    "                    # if len(tokenized_word) > 1:\n",
    "                    #     print([mapper[x]] + [PAD_TOKEN]*(len(tokenized_word)-1))\n",
    "                else:\n",
    "                    tmp_seq.extend(mapper[self.unk])\n",
    "                \n",
    "            res.append([PAD_TOKEN]+tmp_seq+[PAD_TOKEN]) # add the [CLS] and [SEP] to the entire sequence\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "536b67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BertIntentsAndSlots(train_raw, lang)\n",
    "dev_dataset = BertIntentsAndSlots(dev_raw, lang)\n",
    "test_dataset = BertIntentsAndSlots(test_raw, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e886e510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5982/1555882763.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'ids': torch.tensor(ids, dtype=torch.long),\n",
      "/tmp/ipykernel_5982/1555882763.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'mask': torch.tensor(mask, dtype=torch.long),\n",
      "/tmp/ipykernel_5982/1555882763.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['[CLS]',\n",
       "  'what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'earliest',\n",
       "  'flight',\n",
       "  'from',\n",
       "  'oakland',\n",
       "  'to',\n",
       "  'washington',\n",
       "  'dc',\n",
       "  'on',\n",
       "  'sunday',\n",
       "  '[SEP]'],\n",
       " {'ids': tensor([[ 101, 2054, 2003, 1996, 3465, 2005, 2122, 7599, 2013, 6222, 2000, 4407,\n",
       "            102]]),\n",
       "  'mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       "  'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       "  'slots': tensor([ 0, 17, 17, 17, 17, 17, 17, 17, 17, 41, 17, 40,  0]),\n",
       "  'intent': 25})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(train_dataset[4][\"ids\"][0]), train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96adc32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(data):\n",
    "\n",
    "    def merge(sequences):\n",
    "        '''\n",
    "        merge from batch * sent_len to batch * max_len \n",
    "        '''\n",
    "        # print(sequences)\n",
    "        lengths = [max(seq.shape) for seq in sequences]\n",
    "        max_len = 1 if max(lengths)==0 else max(lengths)\n",
    "        # Pad token is zero in our case\n",
    "        # So we create a matrix full of PAD_TOKEN (i.e. 0) with the shape \n",
    "        # batch_size X maximum length of a sequence\n",
    "        padded_seqs = torch.LongTensor(len(sequences),max_len).fill_(PAD_TOKEN)\n",
    "        for i, seq in enumerate(sequences):\n",
    "            end = lengths[i]\n",
    "            padded_seqs[i, :end] = seq # We copy each sequence into the matrix\n",
    "        # print(padded_seqs)\n",
    "        padded_seqs = padded_seqs.detach()  # We remove these tensors from the computational graph\n",
    "        # print(type(padded_seqs), type(lengths), len(padded_seqs), len(lengths))\n",
    "        return padded_seqs, lengths\n",
    "    \n",
    "    # create an empty array of -100 of length max_length\n",
    "    # encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "\n",
    "    # Sort data by seq lengths\n",
    "    data.sort(key=lambda x: len(x['ids']), reverse=True) \n",
    "    new_item = {}\n",
    "    for key in data[0].keys():\n",
    "        new_item[key] = [d[key] for d in data]\n",
    "    \n",
    "\n",
    "    # We just need one length for packed pad seq, since len(utt) == len(slots)\n",
    "    src_utt, _ = merge(new_item['ids'])\n",
    "    src_utt.to(device)\n",
    "    mask, _ = merge(new_item['mask'])\n",
    "    mask.to(device)\n",
    "    token_type_ids, _ = merge(new_item['token_type_ids'])\n",
    "    token_type_ids.to(device)\n",
    "    y_slots, y_lengths = merge(new_item[\"slots\"])\n",
    "    y_slots.to(device)\n",
    "    # y_lengths.to(device)\n",
    "    intent = torch.LongTensor(new_item[\"intent\"]).to(device)\n",
    "    intent.to(device)\n",
    "    # print(100*'*')\n",
    "    # print(y_slots.shape)\n",
    "    # print(100*'*')\n",
    "    \n",
    "    new_item[\"ids\"] = src_utt\n",
    "    new_item[\"mask\"] = mask\n",
    "    new_item[\"token_type_ids\"] = token_type_ids\n",
    "    new_item[\"intents\"] = intent\n",
    "    new_item[\"y_slots\"] = y_slots\n",
    "    new_item[\"slots_len\"] = y_lengths\n",
    "    return new_item\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, collate_fn=collate_fn,  shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=64, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43edb9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5982/1555882763.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'ids': torch.tensor(ids, dtype=torch.long),\n",
      "/tmp/ipykernel_5982/1555882763.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'mask': torch.tensor(mask, dtype=torch.long),\n",
      "/tmp/ipykernel_5982/1555882763.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[ 101, 2054, 2003, 1996, 3465, 2005, 2122, 7599, 2013, 6222, 2000, 4407,\n",
       "           102]]),\n",
       " 'mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'slots': tensor([ 0, 17, 17, 17, 17, 17, 17, 17, 17, 41, 17, 40,  0]),\n",
       " 'intent': 25}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1d712e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5982/1555882763.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'ids': torch.tensor(ids, dtype=torch.long),\n",
      "/tmp/ipykernel_5982/1555882763.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'mask': torch.tensor(mask, dtype=torch.long),\n",
      "/tmp/ipykernel_5982/1555882763.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 17, 17,  ...,  0,  0,  0],\n",
       "        [ 0, 17, 17,  ...,  0,  0,  0],\n",
       "        [ 0, 17, 17,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 0, 17, 17,  ...,  0,  0,  0],\n",
       "        [ 0, 17, 17,  ...,  0,  0,  0],\n",
       "        [ 0, 17, 17,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))['y_slots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dbd92e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 130)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_int, out_slot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9f6d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertJoint(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertJoint, self).__init__()\n",
    "\n",
    "        # Load pre-trained BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # Freeze BERT layers and replace top layers\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Define output layers for multi-task learning\n",
    "        self.slot_classifier = nn.Linear(self.bert.config.hidden_size, out_slot) # token-label classifcation head\n",
    "        self.intent_classifier = nn.Linear(self.bert.config.hidden_size, out_int) # sentence classification head\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids,):\n",
    "        slots, intent = self.bert(input_ids, attention_mask, token_type_ids, return_dict=False) # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "\n",
    "        slot_logits = self.slot_classifier(slots)\n",
    "        intent_logits = self.intent_classifier(intent)\n",
    "        return slot_logits, intent_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "469f7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(data, optimizer, criterion_slots, criterion_intents, model, clip=5):\n",
    "    model.train()\n",
    "    loss_array = []\n",
    "    for sample in data:\n",
    "        optimizer.zero_grad() # Zeroing the gradient\n",
    "        slots, intent = model(sample['ids'], attention_mask=sample['mask'], token_type_ids=sample['token_type_ids'])\n",
    "        # _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        # print(slots.shape, intent.shape)\n",
    "        # print(sample['y_slots'].shape, sample['intents'].shape)\n",
    "        slots = slots.permute(0,2,1) # to compute loss is necessary to permute\n",
    "        loss_intent = criterion_intents(intent.to(device), sample['intents'])\n",
    "        loss_slot = criterion_slots(slots.to(device), sample['y_slots'].to(device))\n",
    "        loss = loss_intent + loss_slot # In joint training we sum the losses. \n",
    "                                       # Is there another way to do that?\n",
    "        loss_array.append(loss.item())\n",
    "        loss.backward() # Compute the gradient, deleting the computational graph\n",
    "        # clip the gradient to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  \n",
    "        optimizer.step() # Update the weights\n",
    "    return loss_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4da8bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(data, criterion_slots, criterion_intents, model, lang):\n",
    "    model.eval()\n",
    "    loss_array = []\n",
    "    \n",
    "    ref_intents = []\n",
    "    hyp_intents = []\n",
    "    \n",
    "    ref_slots = []\n",
    "    hyp_slots = []\n",
    "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
    "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
    "        for sample in data:\n",
    "            slots, intents = model(sample['ids'], attention_mask=sample['mask'], token_type_ids=sample['token_type_ids'])\n",
    "            # slots, intents = model(sample['utterances'], sample['slots_len'])\n",
    "            slots = slots.permute(0,2,1)\n",
    "\n",
    "            loss_intent = criterion_intents(intents.to(device), sample['intents'])\n",
    "            loss_slot = criterion_slots(slots.to(device), sample['y_slots'].to(device))\n",
    "            print(\"loss_slot = %.2f\" % loss_slot)\n",
    "            loss = loss_intent + loss_slot\n",
    "            loss_array.append(loss.item())\n",
    "            # Intent inference\n",
    "            # Get the highest probable class\n",
    "            # print(intents.shape)\n",
    "            # print(torch.argmax(intents, dim=1))\n",
    "\n",
    "            out_intents = [lang.id2intent[x]\n",
    "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
    "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
    "            ref_intents.extend(gt_intents)\n",
    "            hyp_intents.extend(out_intents)\n",
    "            \n",
    "            # Slot inference\n",
    "            output_slots = torch.argmax(slots, dim=1)\n",
    "            for id_seq, seq in enumerate(output_slots):\n",
    "                length = sample['slots_len'][id_seq]\n",
    "                utt_ids = sample['ids'][id_seq][:length].tolist() # get the sequence without the padding 0s\n",
    "                gt_ids = sample['y_slots'][id_seq].tolist()\n",
    "                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n",
    "                utterance = tokenizer.convert_ids_to_tokens(utt_ids)\n",
    "                # utterance = [lang.id2word[elem] for elem in utt_ids]\n",
    "                to_decode = seq[:length].tolist()\n",
    "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
    "                tmp_seq = []\n",
    "                for id_el, elem in enumerate(to_decode):\n",
    "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]))\n",
    "                hyp_slots.append(tmp_seq)\n",
    "    try:            \n",
    "        results = evaluate(ref_slots, hyp_slots)\n",
    "    except Exception as ex:\n",
    "        # Sometimes the model predicts a class that is not in REF\n",
    "        print(\"Warning:\", ex)\n",
    "        ref_s = set([x[1] for x in ref_slots])\n",
    "        hyp_s = set([x[1] for x in hyp_slots])\n",
    "        print(hyp_s.difference(ref_s))\n",
    "        results = {\"total\":{\"f\":0}}\n",
    "        \n",
    "    report_intent = classification_report(ref_intents, hyp_intents, \n",
    "                                          zero_division=False, output_dict=True)\n",
    "    return results, report_intent, loss_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69c12c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/299 [00:00<?, ?it/s]/tmp/ipykernel_5982/1555882763.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'ids': torch.tensor(ids, dtype=torch.long),\n",
      "/tmp/ipykernel_5982/1555882763.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'mask': torch.tensor(mask, dtype=torch.long),\n",
      "/tmp/ipykernel_5982/1555882763.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
      "  1%|          | 2/299 [02:58<7:21:20, 89.16s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb Cell 69\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m best_f1 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,n_epochs)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loss \u001b[39m=\u001b[39m train_loop(train_loader, optimizer, criterion_slots, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                       criterion_intents, bert_model, clip\u001b[39m=\u001b[39;49mclip)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m x \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39m# We check the performance every 5 epochs\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         sampled_epochs\u001b[39m.\u001b[39mappend(x)\n",
      "\u001b[1;32m/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb Cell 69\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m data:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad() \u001b[39m# Zeroing the gradient\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     slots, intent \u001b[39m=\u001b[39m model(sample[\u001b[39m'\u001b[39;49m\u001b[39mids\u001b[39;49m\u001b[39m'\u001b[39;49m], attention_mask\u001b[39m=\u001b[39;49msample[\u001b[39m'\u001b[39;49m\u001b[39mmask\u001b[39;49m\u001b[39m'\u001b[39;49m], token_type_ids\u001b[39m=\u001b[39;49msample[\u001b[39m'\u001b[39;49m\u001b[39mtoken_type_ids\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# print(slots.shape, intent.shape)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# print(sample['y_slots'].shape, sample['intents'].shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     slots \u001b[39m=\u001b[39m slots\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m) \u001b[39m# to compute loss is necessary to permute\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb Cell 69\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask, token_type_ids,):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     slots, intent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(input_ids, attention_mask, token_type_ids, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39m# sequence_output, pooled_output, (hidden_states), (attentions)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     slot_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslot_classifier(slots)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juancm/trento/nlu/my_fork/NLU-2024-Labs/labs/05_intent_and_slot_filling.ipynb#Y125sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     intent_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintent_classifier(intent)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1006\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1007\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1008\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1012\u001b[0m )\n\u001b[0;32m-> 1013\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1014\u001b[0m     embedding_output,\n\u001b[1;32m   1015\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1016\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1017\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1018\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1019\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1020\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1021\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1022\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1023\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1024\u001b[0m )\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1026\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    596\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    597\u001b[0m         layer_module\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         output_attentions,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    608\u001b[0m         hidden_states,\n\u001b[1;32m    609\u001b[0m         attention_mask,\n\u001b[1;32m    610\u001b[0m         layer_head_mask,\n\u001b[1;32m    611\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    612\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    613\u001b[0m         past_key_value,\n\u001b[1;32m    614\u001b[0m         output_attentions,\n\u001b[1;32m    615\u001b[0m     )\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    536\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    537\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 539\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    540\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    541\u001b[0m )\n\u001b[1;32m    542\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    544\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/transformers/pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 237\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> 551\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    552\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    553\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:451\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 451\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    452\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu24/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bert_model = BertJoint()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(bert_model.parameters(), lr=0.0001)\n",
    "criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "criterion_intents = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 50\n",
    "patience = 5\n",
    "losses_train = []\n",
    "losses_dev = []\n",
    "sampled_epochs = []\n",
    "best_f1 = 0\n",
    "for x in tqdm(range(1,n_epochs)):\n",
    "    loss = train_loop(train_loader, optimizer, criterion_slots, \n",
    "                      criterion_intents, bert_model, clip=clip)\n",
    "    if x % 5 == 0: # We check the performance every 5 epochs\n",
    "        sampled_epochs.append(x)\n",
    "        losses_train.append(np.asarray(loss).mean())\n",
    "        results_dev, intent_res, loss_dev = eval_loop(dev_loader, criterion_slots, \n",
    "                                                      criterion_intents, model, lang)\n",
    "        losses_dev.append(np.asarray(loss_dev).mean())\n",
    "        \n",
    "        f1 = results_dev['total']['f']\n",
    "        # For decreasing the patience you can also use the average between slot f1 and intent accuracy\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            # Here you should save the model\n",
    "            patience = 5\n",
    "        else:\n",
    "            patience -= 1\n",
    "        if patience <= 0: # Early stopping with patience\n",
    "            break # Not nice but it keeps the code clean\n",
    "\n",
    "results_test, intent_test, _ = eval_loop(test_loader, criterion_slots, \n",
    "                                         criterion_intents, model, lang)    \n",
    "print('Slot F1: ', results_test['total']['f'])\n",
    "print('Intent Accuracy:', intent_test['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aa13a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flight+airfare': 0,\n",
       " 'flight+airline': 1,\n",
       " 'flight_no': 2,\n",
       " 'airfare+flight': 3,\n",
       " 'flight_no+airline': 4,\n",
       " 'abbreviation': 5,\n",
       " 'day_name': 6,\n",
       " 'capacity': 7,\n",
       " 'quantity': 8,\n",
       " 'cheapest': 9,\n",
       " 'airport': 10,\n",
       " 'ground_service': 11,\n",
       " 'flight_time': 12,\n",
       " 'aircraft+flight+flight_no': 13,\n",
       " 'airline+flight_no': 14,\n",
       " 'distance': 15,\n",
       " 'restriction': 16,\n",
       " 'flight': 17,\n",
       " 'airfare+flight_time': 18,\n",
       " 'meal': 19,\n",
       " 'ground_service+ground_fare': 20,\n",
       " 'city': 21,\n",
       " 'ground_fare': 22,\n",
       " 'airfare': 23,\n",
       " 'aircraft': 24,\n",
       " 'airline': 25}"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang.intent2id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
